{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "871053dd-ae7d-4136-bee8-d927ab31faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from SmilesEnumerator import SmilesEnumerator\n",
    "sme = SmilesEnumerator() \n",
    "\n",
    "import tensorflow as tf\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "import random\n",
    "size = (120, 120) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e958f4c-28ea-4ab0-b169-d0e9a6e646cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Cc1nc(C[NH+]2CCC[C@@H]2c2c(C)n[nH]c2C)sc1C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>CC(C)(O)CNC(=O)NCCCCC1CCCC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Cc1c(CCC(=O)NCCN2CCOCC2)c(=O)oc2cc3oc4c(c3cc12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>C=CCC[C@H](C)OC(=O)c1sc(-c2c(C)c(C)nn(C)c2=O)nc1C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0                CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\n",
       "1           C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1\n",
       "2      N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...\n",
       "3      CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...\n",
       "4      N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...\n",
       "...                                                  ...\n",
       "99995         Cc1nc(C[NH+]2CCC[C@@H]2c2c(C)n[nH]c2C)sc1C\n",
       "99996                        CC(C)(O)CNC(=O)NCCCCC1CCCC1\n",
       "99997  Cc1c(CCC(=O)NCCN2CCOCC2)c(=O)oc2cc3oc4c(c3cc12...\n",
       "99998  C=CCC[C@H](C)OC(=O)c1sc(-c2c(C)c(C)nn(C)c2=O)nc1C\n",
       "99999  CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('100k.txt',header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffc77b4-94f8-4c9c-8151-3e431981a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "for i in range(100000):\n",
    "    for j in range(5):\n",
    "        x.append(sme.randomize_smiles(data.iloc[i,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154d7820-e7b5-4123-be21-4cedc786451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=[]\n",
    "for i in range(100000):\n",
    "    for j in range(5):\n",
    "        target.append(data.iloc[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34f1c6b-24bb-4518-822f-3892c2054846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C(Nc1ccccc1F)(Cc1c2c(oc1)ccc(C(C)(C)C)c2)=O</td>\n",
       "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c1cccc(F)c1NC(=O)Cc1coc2ccc(C(C)(C)C)cc21</td>\n",
       "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1(NC(=O)Cc2coc3c2cc(C(C)(C)C)cc3)c(F)cccc1</td>\n",
       "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c1(C(C)(C)C)cc2c(cc1)occ2CC(Nc1c(F)cccc1)=O</td>\n",
       "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1c(F)c(NC(Cc2coc3ccc(C(C)(C)C)cc32)=O)ccc1</td>\n",
       "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>C1(=O)[C@](C)(c2ccc(C#N)cc2)NC(=O)N1Cc1nc(CCC(...</td>\n",
       "      <td>CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>C[C@]1(c2ccc(C#N)cc2)C(=O)N(Cc2csc(CCC(C)C)n2)...</td>\n",
       "      <td>CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>C(C)(CCc1scc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C...</td>\n",
       "      <td>CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>c1c([C@]2(C)NC(=O)N(Cc3csc(CCC(C)C)n3)C2=O)ccc...</td>\n",
       "      <td>CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>n1c(CCC(C)C)scc1CN1C(=O)[C@](C)(c2ccc(C#N)cc2)...</td>\n",
       "      <td>CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0  \\\n",
       "0             C(Nc1ccccc1F)(Cc1c2c(oc1)ccc(C(C)(C)C)c2)=O   \n",
       "1               c1cccc(F)c1NC(=O)Cc1coc2ccc(C(C)(C)C)cc21   \n",
       "2             c1(NC(=O)Cc2coc3c2cc(C(C)(C)C)cc3)c(F)cccc1   \n",
       "3             c1(C(C)(C)C)cc2c(cc1)occ2CC(Nc1c(F)cccc1)=O   \n",
       "4             c1c(F)c(NC(Cc2coc3ccc(C(C)(C)C)cc32)=O)ccc1   \n",
       "...                                                   ...   \n",
       "499995  C1(=O)[C@](C)(c2ccc(C#N)cc2)NC(=O)N1Cc1nc(CCC(...   \n",
       "499996  C[C@]1(c2ccc(C#N)cc2)C(=O)N(Cc2csc(CCC(C)C)n2)...   \n",
       "499997  C(C)(CCc1scc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C...   \n",
       "499998  c1c([C@]2(C)NC(=O)N(Cc3csc(CCC(C)C)n3)C2=O)ccc...   \n",
       "499999  n1c(CCC(C)C)scc1CN1C(=O)[C@](C)(c2ccc(C#N)cc2)...   \n",
       "\n",
       "                                                        1  \n",
       "0                 CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1  \n",
       "1                 CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1  \n",
       "2                 CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1  \n",
       "3                 CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1  \n",
       "4                 CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1  \n",
       "...                                                   ...  \n",
       "499995  CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...  \n",
       "499996  CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...  \n",
       "499997  CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...  \n",
       "499998  CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...  \n",
       "499999  CC(C)CCc1nc(CN2C(=O)N[C@@](C)(c3ccc(C#N)cc3)C2...  \n",
       "\n",
       "[500000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summa=[]\n",
    "summa.append(x)\n",
    "summa.append(target)\n",
    "summa=np.array(summa).T\n",
    "dataset=pd.DataFrame(summa)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c130373f-53dc-40d8-87a0-29efddaf4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f170c96e-86e8-41ff-8d79-7ddd34d0483f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d6e5b701ab43e48aa39f39cb1a6963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb37041aff4404ba496291d222cd5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/503k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1cd94e57792488f997fe2dd24612b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/357k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"rifkat/pubchem_1M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901d524e-c924-4da4-bb8f-8fbee3aa9bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "def Train_Test(x):\n",
    "    train_data, ts_data = model_selection.train_test_split(x,shuffle=True, test_size = 0.2)\n",
    "    def Train_Test1(x):\n",
    "        tr_data, te_data = model_selection.train_test_split(x,shuffle=True, test_size = 0.5)\n",
    "        return tr_data, te_data\n",
    "    valid_data, test_data = Train_Test1(ts_data)\n",
    "    return train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72095699-e3f5-4872-a4f6-42d4f9db7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df = Train_Test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3916f53-8e2d-4bcb-af2c-6b288e7a9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_x=tf.ragged.constant(np.array(train_df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True))))).to_tensor().numpy()\n",
    "ds_y=tf.ragged.constant(np.array(train_df[1].apply((lambda x: tokenizer.encode(x, add_special_tokens=True))))).to_tensor().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af478722-10f5-4e22-9b3d-2b2f29d0c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d23d2a39-5f5d-4deb-82b7-29e8d27a8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "  \n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "  \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "  \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66812df5-7f7d-4e04-94c1-536ac9e03445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20c48ef0-2d1a-43b9-82fe-b3cdd81cbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04fefe65-b39c-4799-b305-f1e43ee36a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "      \n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "  \n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "  \n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "  \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e9081b9-5e0a-4dc3-9854-5e27c84073ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "  \n",
    "        assert d_model % self.num_heads == 0\n",
    "  \n",
    "        self.depth = d_model // self.num_heads\n",
    "  \n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "  \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "  \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "  \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "    \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "    \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "    \n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "    \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "    \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "579deb53-6b5b-4e76-9366-ee98e10d5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c1bc724-5997-4410-a8c4-bafcd18cf908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "  \n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "  \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eac1f658-7d71-4dbe-a911-5a0a421f3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "             look_ahead_mask, padding_mask):\n",
    "      # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37e34c51-16a5-4d53-9d6f-d69c7b2e1a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                                self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52ac37f9-1c6d-48d0-9324-4a7d64512548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5332ec31-d2e7-43be-b8f6-5172603f5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "  \n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "  \n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "  \n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "  \n",
    "    def call(self, x, enc_output, training,\n",
    "             look_ahead_mask, padding_mask):\n",
    "  \n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "  \n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "  \n",
    "        x = self.dropout(x, training=training)\n",
    "  \n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "  \n",
    "            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "  \n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b639a5e7-5804-4c7d-827e-56ce8dd497ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "  \n",
    "        self.tokenizer = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                                 input_vocab_size, pe_input, rate)\n",
    "  \n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, rate)\n",
    "  \n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask,\n",
    "             look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae5d39da-a674-4b61-ba91-da4da647b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3e03ec6-a888-4ada-bc4b-8163ceb4d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "  \n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "  \n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32447f9c-8d17-4188-82b3-69dc25664637",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83c47adc-9d72-40cc-a863-7e2c1208e00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7526cda6-534a-4465-9e4f-2e30c8cc15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "543a897a-aaf7-4aa9-83bc-a7db4abc79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "#     print(real,'loss_function')\n",
    "#     print(pred,'loss_function')\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "#     print(real,'accuracy_function')\n",
    "#     print(pred,'accuracy_function')\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b2de1e0-9272-4500-9b69-0d1fc7bf5c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bfa60d16-fce9-4a56-a4fd-ac00820d2e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizer.vocab_size,\n",
    "    target_vocab_size=tokenizer.vocab_size,\n",
    "    pe_input=1000,\n",
    "    pe_target=1000,\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90f63766-d8cb-40a3-bf82-bfa91686104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a30fee9-a970-42c6-8bd4-ca1e8546be7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a40533f7-5c0b-4220-9130-316d575dc4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a43d8507-71f6-4c89-8dd3-d43aad1f1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp,\n",
    "                                   True,\n",
    "                                   enc_padding_mask,\n",
    "                                   combined_mask,\n",
    "                                   dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "720ee0f1-f15a-4cad-aaa7-e1487a45ad5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function train_step at 0x7f7a9dc9a700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Encoder.call of <__main__.Encoder object at 0x7f7b50053250>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MultiHeadAttention.call of <__main__.MultiHeadAttention object at 0x7f7a9e86c400>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Decoder.call of <__main__.Decoder object at 0x7f7a9dcaf3d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1 Batch 0 Loss 8.9545 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.8321 Accuracy 0.0203\n",
      "Epoch 1 Batch 100 Loss 8.6429 Accuracy 0.0592\n",
      "Epoch 1 Batch 150 Loss 8.4337 Accuracy 0.0728\n",
      "Epoch 1 Batch 200 Loss 8.1687 Accuracy 0.0808\n",
      "Epoch 1 Batch 250 Loss 7.8412 Accuracy 0.0878\n",
      "Epoch 1 Batch 300 Loss 7.4600 Accuracy 0.0988\n",
      "Epoch 1 Batch 350 Loss 7.0542 Accuracy 0.1208\n",
      "Epoch 1 Batch 400 Loss 6.6606 Accuracy 0.1440\n",
      "Epoch 1 Batch 450 Loss 6.2989 Accuracy 0.1700\n",
      "Epoch 1 Batch 500 Loss 5.9637 Accuracy 0.1979\n",
      "Epoch 1 Batch 550 Loss 5.6488 Accuracy 0.2246\n",
      "Epoch 1 Batch 600 Loss 5.3599 Accuracy 0.2487\n",
      "Epoch 1 Batch 650 Loss 5.0968 Accuracy 0.2710\n",
      "Epoch 1 Batch 700 Loss 4.8604 Accuracy 0.2910\n",
      "Epoch 1 Batch 750 Loss 4.6470 Accuracy 0.3097\n",
      "Epoch 1 Batch 800 Loss 4.4542 Accuracy 0.3268\n",
      "Epoch 1 Batch 850 Loss 4.2800 Accuracy 0.3427\n",
      "Epoch 1 Batch 900 Loss 4.1203 Accuracy 0.3578\n",
      "Epoch 1 Batch 950 Loss 3.9752 Accuracy 0.3715\n",
      "Epoch 1 Batch 1000 Loss 3.8420 Accuracy 0.3844\n",
      "Epoch 1 Batch 1050 Loss 3.7190 Accuracy 0.3966\n",
      "Epoch 1 Batch 1100 Loss 3.6057 Accuracy 0.4080\n",
      "Epoch 1 Batch 1150 Loss 3.5003 Accuracy 0.4188\n",
      "Epoch 1 Batch 1200 Loss 3.4020 Accuracy 0.4291\n",
      "Epoch 1 Batch 1250 Loss 3.3107 Accuracy 0.4388\n",
      "Epoch 1 Batch 1300 Loss 3.2250 Accuracy 0.4481\n",
      "Epoch 1 Batch 1350 Loss 3.1449 Accuracy 0.4569\n",
      "Epoch 1 Batch 1400 Loss 3.0696 Accuracy 0.4653\n",
      "Epoch 1 Batch 1450 Loss 2.9983 Accuracy 0.4734\n",
      "Epoch 1 Batch 1500 Loss 2.9313 Accuracy 0.4810\n",
      "Epoch 1 Batch 1550 Loss 2.8676 Accuracy 0.4884\n",
      "Epoch 1 Batch 1600 Loss 2.8077 Accuracy 0.4954\n",
      "Epoch 1 Batch 1650 Loss 2.7509 Accuracy 0.5020\n",
      "Epoch 1 Batch 1700 Loss 2.6969 Accuracy 0.5085\n",
      "Epoch 1 Batch 1750 Loss 2.6458 Accuracy 0.5146\n",
      "Epoch 1 Batch 1800 Loss 2.5971 Accuracy 0.5204\n",
      "Epoch 1 Batch 1850 Loss 2.5507 Accuracy 0.5261\n",
      "Epoch 1 Batch 1900 Loss 2.5062 Accuracy 0.5315\n",
      "Epoch 1 Batch 1950 Loss 2.4637 Accuracy 0.5368\n",
      "Epoch 1 Batch 2000 Loss 2.4227 Accuracy 0.5419\n",
      "Epoch 1 Batch 2050 Loss 2.3837 Accuracy 0.5468\n",
      "Epoch 1 Batch 2100 Loss 2.3463 Accuracy 0.5515\n",
      "Epoch 1 Batch 2150 Loss 2.3102 Accuracy 0.5561\n",
      "Epoch 1 Batch 2200 Loss 2.2757 Accuracy 0.5604\n",
      "Epoch 1 Batch 2250 Loss 2.2424 Accuracy 0.5647\n",
      "Epoch 1 Batch 2300 Loss 2.2102 Accuracy 0.5689\n",
      "Epoch 1 Batch 2350 Loss 2.1794 Accuracy 0.5728\n",
      "Epoch 1 Batch 2400 Loss 2.1495 Accuracy 0.5768\n",
      "Epoch 1 Batch 2450 Loss 2.1205 Accuracy 0.5806\n",
      "Epoch 1 Batch 2500 Loss 2.0924 Accuracy 0.5843\n",
      "Epoch 1 Batch 2550 Loss 2.0654 Accuracy 0.5880\n",
      "Epoch 1 Batch 2600 Loss 2.0389 Accuracy 0.5915\n",
      "Epoch 1 Batch 2650 Loss 2.0133 Accuracy 0.5950\n",
      "Epoch 1 Batch 2700 Loss 1.9885 Accuracy 0.5985\n",
      "Epoch 1 Batch 2750 Loss 1.9644 Accuracy 0.6017\n",
      "Epoch 1 Batch 2800 Loss 1.9411 Accuracy 0.6050\n",
      "Epoch 1 Batch 2850 Loss 1.9181 Accuracy 0.6082\n",
      "Epoch 1 Batch 2900 Loss 1.8960 Accuracy 0.6113\n",
      "Epoch 1 Batch 2950 Loss 1.8743 Accuracy 0.6144\n",
      "Epoch 1 Batch 3000 Loss 1.8533 Accuracy 0.6174\n",
      "Epoch 1 Batch 3050 Loss 1.8330 Accuracy 0.6203\n",
      "Epoch 1 Batch 3100 Loss 1.8131 Accuracy 0.6231\n",
      "Epoch 1 Batch 3150 Loss 1.7937 Accuracy 0.6259\n",
      "Epoch 1 Batch 3200 Loss 1.7749 Accuracy 0.6286\n",
      "Epoch 1 Batch 3250 Loss 1.7566 Accuracy 0.6313\n",
      "Epoch 1 Batch 3300 Loss 1.7387 Accuracy 0.6339\n",
      "Epoch 1 Batch 3350 Loss 1.7213 Accuracy 0.6365\n",
      "Epoch 1 Batch 3400 Loss 1.7041 Accuracy 0.6390\n",
      "Epoch 1 Batch 3450 Loss 1.6876 Accuracy 0.6414\n",
      "Epoch 1 Batch 3500 Loss 1.6713 Accuracy 0.6439\n",
      "Epoch 1 Batch 3550 Loss 1.6557 Accuracy 0.6462\n",
      "Epoch 1 Batch 3600 Loss 1.6403 Accuracy 0.6485\n",
      "Epoch 1 Batch 3650 Loss 1.6252 Accuracy 0.6507\n",
      "Epoch 1 Batch 3700 Loss 1.6104 Accuracy 0.6530\n",
      "Epoch 1 Batch 3750 Loss 1.5959 Accuracy 0.6552\n",
      "Epoch 1 Batch 3800 Loss 1.5817 Accuracy 0.6574\n",
      "Epoch 1 Batch 3850 Loss 1.5678 Accuracy 0.6595\n",
      "Epoch 1 Batch 3900 Loss 1.5543 Accuracy 0.6616\n",
      "Epoch 1 Batch 3950 Loss 1.5410 Accuracy 0.6637\n",
      "Epoch 1 Batch 4000 Loss 1.5281 Accuracy 0.6657\n",
      "Epoch 1 Batch 4050 Loss 1.5152 Accuracy 0.6678\n",
      "Epoch 1 Batch 4100 Loss 1.5025 Accuracy 0.6698\n",
      "Epoch 1 Batch 4150 Loss 1.4901 Accuracy 0.6718\n",
      "Epoch 1 Batch 4200 Loss 1.4778 Accuracy 0.6738\n",
      "Epoch 1 Batch 4250 Loss 1.4659 Accuracy 0.6757\n",
      "Epoch 1 Batch 4300 Loss 1.4542 Accuracy 0.6777\n",
      "Epoch 1 Batch 4350 Loss 1.4426 Accuracy 0.6796\n",
      "Epoch 1 Batch 4400 Loss 1.4311 Accuracy 0.6815\n",
      "Epoch 1 Batch 4450 Loss 1.4200 Accuracy 0.6833\n",
      "Epoch 1 Batch 4500 Loss 1.4090 Accuracy 0.6852\n",
      "Epoch 1 Batch 4550 Loss 1.3981 Accuracy 0.6870\n",
      "Epoch 1 Batch 4600 Loss 1.3874 Accuracy 0.6888\n",
      "Epoch 1 Batch 4650 Loss 1.3769 Accuracy 0.6906\n",
      "Epoch 1 Batch 4700 Loss 1.3664 Accuracy 0.6925\n",
      "Epoch 1 Batch 4750 Loss 1.3562 Accuracy 0.6942\n",
      "Epoch 1 Batch 4800 Loss 1.3461 Accuracy 0.6960\n",
      "Epoch 1 Batch 4850 Loss 1.3362 Accuracy 0.6977\n",
      "Epoch 1 Batch 4900 Loss 1.3265 Accuracy 0.6994\n",
      "Epoch 1 Batch 4950 Loss 1.3168 Accuracy 0.7011\n",
      "Epoch 1 Batch 5000 Loss 1.3073 Accuracy 0.7028\n",
      "Epoch 1 Batch 5050 Loss 1.2980 Accuracy 0.7045\n",
      "Epoch 1 Batch 5100 Loss 1.2887 Accuracy 0.7062\n",
      "Epoch 1 Batch 5150 Loss 1.2796 Accuracy 0.7078\n",
      "Epoch 1 Batch 5200 Loss 1.2707 Accuracy 0.7094\n",
      "Epoch 1 Batch 5250 Loss 1.2619 Accuracy 0.7110\n",
      "Epoch 1 Batch 5300 Loss 1.2532 Accuracy 0.7126\n",
      "Epoch 1 Batch 5350 Loss 1.2446 Accuracy 0.7142\n",
      "Epoch 1 Batch 5400 Loss 1.2361 Accuracy 0.7158\n",
      "Epoch 1 Batch 5450 Loss 1.2278 Accuracy 0.7173\n",
      "Epoch 1 Batch 5500 Loss 1.2194 Accuracy 0.7189\n",
      "Epoch 1 Batch 5550 Loss 1.2113 Accuracy 0.7204\n",
      "Epoch 1 Batch 5600 Loss 1.2033 Accuracy 0.7219\n",
      "Epoch 1 Batch 5650 Loss 1.1954 Accuracy 0.7234\n",
      "Epoch 1 Batch 5700 Loss 1.1876 Accuracy 0.7249\n",
      "Epoch 1 Batch 5750 Loss 1.1798 Accuracy 0.7263\n",
      "Epoch 1 Batch 5800 Loss 1.1722 Accuracy 0.7278\n",
      "Epoch 1 Batch 5850 Loss 1.1647 Accuracy 0.7292\n",
      "Epoch 1 Batch 5900 Loss 1.1572 Accuracy 0.7307\n",
      "Epoch 1 Batch 5950 Loss 1.1498 Accuracy 0.7321\n",
      "Epoch 1 Batch 6000 Loss 1.1425 Accuracy 0.7335\n",
      "Epoch 1 Batch 6050 Loss 1.1353 Accuracy 0.7349\n",
      "Epoch 1 Batch 6100 Loss 1.1282 Accuracy 0.7363\n",
      "Epoch 1 Batch 6150 Loss 1.1212 Accuracy 0.7377\n",
      "Epoch 1 Batch 6200 Loss 1.1143 Accuracy 0.7390\n",
      "Epoch 1 Loss 1.1077 Accuracy 0.7403\n",
      "Time taken for 1 epoch: 627.14 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.2304 Accuracy 0.9100\n",
      "Epoch 2 Batch 50 Loss 0.2523 Accuracy 0.9082\n",
      "Epoch 2 Batch 100 Loss 0.2547 Accuracy 0.9079\n",
      "Epoch 2 Batch 150 Loss 0.2555 Accuracy 0.9079\n",
      "Epoch 2 Batch 200 Loss 0.2545 Accuracy 0.9083\n",
      "Epoch 2 Batch 250 Loss 0.2539 Accuracy 0.9085\n",
      "Epoch 2 Batch 300 Loss 0.2525 Accuracy 0.9089\n",
      "Epoch 2 Batch 350 Loss 0.2507 Accuracy 0.9094\n",
      "Epoch 2 Batch 400 Loss 0.2494 Accuracy 0.9099\n",
      "Epoch 2 Batch 450 Loss 0.2477 Accuracy 0.9104\n",
      "Epoch 2 Batch 500 Loss 0.2464 Accuracy 0.9108\n",
      "Epoch 2 Batch 550 Loss 0.2444 Accuracy 0.9115\n",
      "Epoch 2 Batch 600 Loss 0.2440 Accuracy 0.9116\n",
      "Epoch 2 Batch 650 Loss 0.2427 Accuracy 0.9121\n",
      "Epoch 2 Batch 700 Loss 0.2415 Accuracy 0.9125\n",
      "Epoch 2 Batch 750 Loss 0.2401 Accuracy 0.9130\n",
      "Epoch 2 Batch 800 Loss 0.2393 Accuracy 0.9133\n",
      "Epoch 2 Batch 850 Loss 0.2382 Accuracy 0.9136\n",
      "Epoch 2 Batch 900 Loss 0.2371 Accuracy 0.9140\n",
      "Epoch 2 Batch 950 Loss 0.2360 Accuracy 0.9144\n",
      "Epoch 2 Batch 1000 Loss 0.2348 Accuracy 0.9148\n",
      "Epoch 2 Batch 1050 Loss 0.2337 Accuracy 0.9152\n",
      "Epoch 2 Batch 1100 Loss 0.2328 Accuracy 0.9155\n",
      "Epoch 2 Batch 1150 Loss 0.2317 Accuracy 0.9159\n",
      "Epoch 2 Batch 1200 Loss 0.2307 Accuracy 0.9162\n",
      "Epoch 2 Batch 1250 Loss 0.2297 Accuracy 0.9166\n",
      "Epoch 2 Batch 1300 Loss 0.2286 Accuracy 0.9170\n",
      "Epoch 2 Batch 1350 Loss 0.2277 Accuracy 0.9173\n",
      "Epoch 2 Batch 1400 Loss 0.2269 Accuracy 0.9176\n",
      "Epoch 2 Batch 1450 Loss 0.2259 Accuracy 0.9180\n",
      "Epoch 2 Batch 1500 Loss 0.2250 Accuracy 0.9183\n",
      "Epoch 2 Batch 1550 Loss 0.2239 Accuracy 0.9187\n",
      "Epoch 2 Batch 1600 Loss 0.2230 Accuracy 0.9190\n",
      "Epoch 2 Batch 1650 Loss 0.2220 Accuracy 0.9193\n",
      "Epoch 2 Batch 1700 Loss 0.2213 Accuracy 0.9195\n",
      "Epoch 2 Batch 1750 Loss 0.2204 Accuracy 0.9198\n",
      "Epoch 2 Batch 1800 Loss 0.2197 Accuracy 0.9201\n",
      "Epoch 2 Batch 1850 Loss 0.2189 Accuracy 0.9203\n",
      "Epoch 2 Batch 1900 Loss 0.2181 Accuracy 0.9206\n",
      "Epoch 2 Batch 1950 Loss 0.2173 Accuracy 0.9209\n",
      "Epoch 2 Batch 2000 Loss 0.2164 Accuracy 0.9212\n",
      "Epoch 2 Batch 2050 Loss 0.2156 Accuracy 0.9215\n",
      "Epoch 2 Batch 2100 Loss 0.2148 Accuracy 0.9217\n",
      "Epoch 2 Batch 2150 Loss 0.2139 Accuracy 0.9220\n",
      "Epoch 2 Batch 2200 Loss 0.2131 Accuracy 0.9223\n",
      "Epoch 2 Batch 2250 Loss 0.2123 Accuracy 0.9226\n",
      "Epoch 2 Batch 2300 Loss 0.2115 Accuracy 0.9228\n",
      "Epoch 2 Batch 2350 Loss 0.2108 Accuracy 0.9231\n",
      "Epoch 2 Batch 2400 Loss 0.2099 Accuracy 0.9234\n",
      "Epoch 2 Batch 2450 Loss 0.2091 Accuracy 0.9236\n",
      "Epoch 2 Batch 2500 Loss 0.2083 Accuracy 0.9239\n",
      "Epoch 2 Batch 2550 Loss 0.2076 Accuracy 0.9242\n",
      "Epoch 2 Batch 2600 Loss 0.2068 Accuracy 0.9244\n",
      "Epoch 2 Batch 2650 Loss 0.2060 Accuracy 0.9247\n",
      "Epoch 2 Batch 2700 Loss 0.2052 Accuracy 0.9249\n",
      "Epoch 2 Batch 2750 Loss 0.2046 Accuracy 0.9251\n",
      "Epoch 2 Batch 2800 Loss 0.2038 Accuracy 0.9254\n",
      "Epoch 2 Batch 2850 Loss 0.2030 Accuracy 0.9257\n",
      "Epoch 2 Batch 2900 Loss 0.2022 Accuracy 0.9260\n",
      "Epoch 2 Batch 2950 Loss 0.2015 Accuracy 0.9262\n",
      "Epoch 2 Batch 3000 Loss 0.2008 Accuracy 0.9264\n",
      "Epoch 2 Batch 3050 Loss 0.2000 Accuracy 0.9267\n",
      "Epoch 2 Batch 3100 Loss 0.1994 Accuracy 0.9269\n",
      "Epoch 2 Batch 3150 Loss 0.1988 Accuracy 0.9271\n",
      "Epoch 2 Batch 3200 Loss 0.1981 Accuracy 0.9273\n",
      "Epoch 2 Batch 3250 Loss 0.1974 Accuracy 0.9276\n",
      "Epoch 2 Batch 3300 Loss 0.1967 Accuracy 0.9278\n",
      "Epoch 2 Batch 3350 Loss 0.1961 Accuracy 0.9280\n",
      "Epoch 2 Batch 3400 Loss 0.1955 Accuracy 0.9282\n",
      "Epoch 2 Batch 3450 Loss 0.1949 Accuracy 0.9284\n",
      "Epoch 2 Batch 3500 Loss 0.1943 Accuracy 0.9286\n",
      "Epoch 2 Batch 3550 Loss 0.1938 Accuracy 0.9288\n",
      "Epoch 2 Batch 3600 Loss 0.1932 Accuracy 0.9290\n",
      "Epoch 2 Batch 3650 Loss 0.1926 Accuracy 0.9292\n",
      "Epoch 2 Batch 3700 Loss 0.1920 Accuracy 0.9294\n",
      "Epoch 2 Batch 3750 Loss 0.1914 Accuracy 0.9296\n",
      "Epoch 2 Batch 3800 Loss 0.1908 Accuracy 0.9298\n",
      "Epoch 2 Batch 3850 Loss 0.1901 Accuracy 0.9300\n",
      "Epoch 2 Batch 3900 Loss 0.1896 Accuracy 0.9302\n",
      "Epoch 2 Batch 3950 Loss 0.1890 Accuracy 0.9304\n",
      "Epoch 2 Batch 4000 Loss 0.1885 Accuracy 0.9306\n",
      "Epoch 2 Batch 4050 Loss 0.1880 Accuracy 0.9308\n",
      "Epoch 2 Batch 4100 Loss 0.1874 Accuracy 0.9309\n",
      "Epoch 2 Batch 4150 Loss 0.1868 Accuracy 0.9311\n",
      "Epoch 2 Batch 4200 Loss 0.1863 Accuracy 0.9313\n",
      "Epoch 2 Batch 4250 Loss 0.1857 Accuracy 0.9315\n",
      "Epoch 2 Batch 4300 Loss 0.1852 Accuracy 0.9317\n",
      "Epoch 2 Batch 4350 Loss 0.1847 Accuracy 0.9319\n",
      "Epoch 2 Batch 4400 Loss 0.1842 Accuracy 0.9320\n",
      "Epoch 2 Batch 4450 Loss 0.1837 Accuracy 0.9322\n",
      "Epoch 2 Batch 4500 Loss 0.1831 Accuracy 0.9324\n",
      "Epoch 2 Batch 4550 Loss 0.1826 Accuracy 0.9325\n",
      "Epoch 2 Batch 4600 Loss 0.1822 Accuracy 0.9327\n",
      "Epoch 2 Batch 4650 Loss 0.1816 Accuracy 0.9329\n",
      "Epoch 2 Batch 4700 Loss 0.1811 Accuracy 0.9331\n",
      "Epoch 2 Batch 4750 Loss 0.1806 Accuracy 0.9332\n",
      "Epoch 2 Batch 4800 Loss 0.1801 Accuracy 0.9334\n",
      "Epoch 2 Batch 4850 Loss 0.1796 Accuracy 0.9336\n",
      "Epoch 2 Batch 4900 Loss 0.1791 Accuracy 0.9337\n",
      "Epoch 2 Batch 4950 Loss 0.1786 Accuracy 0.9339\n",
      "Epoch 2 Batch 5000 Loss 0.1781 Accuracy 0.9341\n",
      "Epoch 2 Batch 5050 Loss 0.1777 Accuracy 0.9342\n",
      "Epoch 2 Batch 5100 Loss 0.1772 Accuracy 0.9344\n",
      "Epoch 2 Batch 5150 Loss 0.1767 Accuracy 0.9346\n",
      "Epoch 2 Batch 5200 Loss 0.1763 Accuracy 0.9347\n",
      "Epoch 2 Batch 5250 Loss 0.1758 Accuracy 0.9349\n",
      "Epoch 2 Batch 5300 Loss 0.1753 Accuracy 0.9350\n",
      "Epoch 2 Batch 5350 Loss 0.1749 Accuracy 0.9352\n",
      "Epoch 2 Batch 5400 Loss 0.1744 Accuracy 0.9353\n",
      "Epoch 2 Batch 5450 Loss 0.1740 Accuracy 0.9355\n",
      "Epoch 2 Batch 5500 Loss 0.1735 Accuracy 0.9356\n",
      "Epoch 2 Batch 5550 Loss 0.1731 Accuracy 0.9358\n",
      "Epoch 2 Batch 5600 Loss 0.1726 Accuracy 0.9359\n",
      "Epoch 2 Batch 5650 Loss 0.1722 Accuracy 0.9361\n",
      "Epoch 2 Batch 5700 Loss 0.1718 Accuracy 0.9362\n",
      "Epoch 2 Batch 5750 Loss 0.1713 Accuracy 0.9364\n",
      "Epoch 2 Batch 5800 Loss 0.1709 Accuracy 0.9365\n",
      "Epoch 2 Batch 5850 Loss 0.1705 Accuracy 0.9366\n",
      "Epoch 2 Batch 5900 Loss 0.1701 Accuracy 0.9368\n",
      "Epoch 2 Batch 5950 Loss 0.1696 Accuracy 0.9369\n",
      "Epoch 2 Batch 6000 Loss 0.1691 Accuracy 0.9371\n",
      "Epoch 2 Batch 6050 Loss 0.1687 Accuracy 0.9372\n",
      "Epoch 2 Batch 6100 Loss 0.1683 Accuracy 0.9374\n",
      "Epoch 2 Batch 6150 Loss 0.1678 Accuracy 0.9375\n",
      "Epoch 2 Batch 6200 Loss 0.1675 Accuracy 0.9377\n",
      "Epoch 2 Loss 0.1671 Accuracy 0.9378\n",
      "Time taken for 1 epoch: 614.13 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.1141 Accuracy 0.9560\n",
      "Epoch 3 Batch 50 Loss 0.1127 Accuracy 0.9561\n",
      "Epoch 3 Batch 100 Loss 0.1153 Accuracy 0.9551\n",
      "Epoch 3 Batch 150 Loss 0.1155 Accuracy 0.9551\n",
      "Epoch 3 Batch 200 Loss 0.1170 Accuracy 0.9545\n",
      "Epoch 3 Batch 250 Loss 0.1172 Accuracy 0.9544\n",
      "Epoch 3 Batch 300 Loss 0.1172 Accuracy 0.9544\n",
      "Epoch 3 Batch 350 Loss 0.1158 Accuracy 0.9550\n",
      "Epoch 3 Batch 400 Loss 0.1156 Accuracy 0.9551\n",
      "Epoch 3 Batch 450 Loss 0.1153 Accuracy 0.9553\n",
      "Epoch 3 Batch 500 Loss 0.1151 Accuracy 0.9554\n",
      "Epoch 3 Batch 550 Loss 0.1143 Accuracy 0.9556\n",
      "Epoch 3 Batch 600 Loss 0.1145 Accuracy 0.9555\n",
      "Epoch 3 Batch 650 Loss 0.1141 Accuracy 0.9556\n",
      "Epoch 3 Batch 700 Loss 0.1138 Accuracy 0.9557\n",
      "Epoch 3 Batch 750 Loss 0.1135 Accuracy 0.9558\n",
      "Epoch 3 Batch 800 Loss 0.1133 Accuracy 0.9560\n",
      "Epoch 3 Batch 850 Loss 0.1132 Accuracy 0.9560\n",
      "Epoch 3 Batch 900 Loss 0.1128 Accuracy 0.9561\n",
      "Epoch 3 Batch 950 Loss 0.1126 Accuracy 0.9561\n",
      "Epoch 3 Batch 1000 Loss 0.1125 Accuracy 0.9562\n",
      "Epoch 3 Batch 1050 Loss 0.1123 Accuracy 0.9563\n",
      "Epoch 3 Batch 1100 Loss 0.1120 Accuracy 0.9563\n",
      "Epoch 3 Batch 1150 Loss 0.1117 Accuracy 0.9564\n",
      "Epoch 3 Batch 1200 Loss 0.1115 Accuracy 0.9565\n",
      "Epoch 3 Batch 1250 Loss 0.1114 Accuracy 0.9565\n",
      "Epoch 3 Batch 1300 Loss 0.1112 Accuracy 0.9566\n",
      "Epoch 3 Batch 1350 Loss 0.1111 Accuracy 0.9566\n",
      "Epoch 3 Batch 1400 Loss 0.1110 Accuracy 0.9567\n",
      "Epoch 3 Batch 1450 Loss 0.1108 Accuracy 0.9567\n",
      "Epoch 3 Batch 1500 Loss 0.1106 Accuracy 0.9568\n",
      "Epoch 3 Batch 1550 Loss 0.1103 Accuracy 0.9569\n",
      "Epoch 3 Batch 1600 Loss 0.1101 Accuracy 0.9569\n",
      "Epoch 3 Batch 1650 Loss 0.1099 Accuracy 0.9570\n",
      "Epoch 3 Batch 1700 Loss 0.1097 Accuracy 0.9571\n",
      "Epoch 3 Batch 1750 Loss 0.1097 Accuracy 0.9571\n",
      "Epoch 3 Batch 1800 Loss 0.1096 Accuracy 0.9571\n",
      "Epoch 3 Batch 1850 Loss 0.1095 Accuracy 0.9572\n",
      "Epoch 3 Batch 1900 Loss 0.1093 Accuracy 0.9572\n",
      "Epoch 3 Batch 1950 Loss 0.1092 Accuracy 0.9573\n",
      "Epoch 3 Batch 2000 Loss 0.1089 Accuracy 0.9574\n",
      "Epoch 3 Batch 2050 Loss 0.1087 Accuracy 0.9574\n",
      "Epoch 3 Batch 2100 Loss 0.1086 Accuracy 0.9575\n",
      "Epoch 3 Batch 2150 Loss 0.1084 Accuracy 0.9576\n",
      "Epoch 3 Batch 2200 Loss 0.1082 Accuracy 0.9576\n",
      "Epoch 3 Batch 2250 Loss 0.1080 Accuracy 0.9577\n",
      "Epoch 3 Batch 2300 Loss 0.1078 Accuracy 0.9578\n",
      "Epoch 3 Batch 2350 Loss 0.1076 Accuracy 0.9578\n",
      "Epoch 3 Batch 2400 Loss 0.1074 Accuracy 0.9579\n",
      "Epoch 3 Batch 2450 Loss 0.1072 Accuracy 0.9580\n",
      "Epoch 3 Batch 2500 Loss 0.1070 Accuracy 0.9581\n",
      "Epoch 3 Batch 2550 Loss 0.1069 Accuracy 0.9581\n",
      "Epoch 3 Batch 2600 Loss 0.1067 Accuracy 0.9582\n",
      "Epoch 3 Batch 2650 Loss 0.1065 Accuracy 0.9582\n",
      "Epoch 3 Batch 2700 Loss 0.1063 Accuracy 0.9583\n",
      "Epoch 3 Batch 2750 Loss 0.1061 Accuracy 0.9583\n",
      "Epoch 3 Batch 2800 Loss 0.1059 Accuracy 0.9584\n",
      "Epoch 3 Batch 2850 Loss 0.1058 Accuracy 0.9584\n",
      "Epoch 3 Batch 2900 Loss 0.1056 Accuracy 0.9585\n",
      "Epoch 3 Batch 2950 Loss 0.1054 Accuracy 0.9586\n",
      "Epoch 3 Batch 3000 Loss 0.1053 Accuracy 0.9586\n",
      "Epoch 3 Batch 3050 Loss 0.1051 Accuracy 0.9587\n",
      "Epoch 3 Batch 3100 Loss 0.1049 Accuracy 0.9587\n",
      "Epoch 3 Batch 3150 Loss 0.1048 Accuracy 0.9588\n",
      "Epoch 3 Batch 3200 Loss 0.1046 Accuracy 0.9588\n",
      "Epoch 3 Batch 3250 Loss 0.1044 Accuracy 0.9589\n",
      "Epoch 3 Batch 3300 Loss 0.1043 Accuracy 0.9589\n",
      "Epoch 3 Batch 3350 Loss 0.1041 Accuracy 0.9590\n",
      "Epoch 3 Batch 3400 Loss 0.1040 Accuracy 0.9590\n",
      "Epoch 3 Batch 3450 Loss 0.1039 Accuracy 0.9591\n",
      "Epoch 3 Batch 3500 Loss 0.1037 Accuracy 0.9591\n",
      "Epoch 3 Batch 3550 Loss 0.1036 Accuracy 0.9592\n",
      "Epoch 3 Batch 3600 Loss 0.1035 Accuracy 0.9592\n",
      "Epoch 3 Batch 3650 Loss 0.1033 Accuracy 0.9593\n",
      "Epoch 3 Batch 3700 Loss 0.1031 Accuracy 0.9593\n",
      "Epoch 3 Batch 3750 Loss 0.1030 Accuracy 0.9594\n",
      "Epoch 3 Batch 3800 Loss 0.1029 Accuracy 0.9594\n",
      "Epoch 3 Batch 3850 Loss 0.1027 Accuracy 0.9595\n",
      "Epoch 3 Batch 3900 Loss 0.1025 Accuracy 0.9595\n",
      "Epoch 3 Batch 3950 Loss 0.1024 Accuracy 0.9596\n",
      "Epoch 3 Batch 4000 Loss 0.1023 Accuracy 0.9596\n",
      "Epoch 3 Batch 4050 Loss 0.1021 Accuracy 0.9597\n",
      "Epoch 3 Batch 4100 Loss 0.1019 Accuracy 0.9597\n",
      "Epoch 3 Batch 4150 Loss 0.1018 Accuracy 0.9598\n",
      "Epoch 3 Batch 4200 Loss 0.1016 Accuracy 0.9598\n",
      "Epoch 3 Batch 4250 Loss 0.1015 Accuracy 0.9599\n",
      "Epoch 3 Batch 4300 Loss 0.1013 Accuracy 0.9599\n",
      "Epoch 3 Batch 4350 Loss 0.1012 Accuracy 0.9600\n",
      "Epoch 3 Batch 4400 Loss 0.1010 Accuracy 0.9600\n",
      "Epoch 3 Batch 4450 Loss 0.1009 Accuracy 0.9600\n",
      "Epoch 3 Batch 4500 Loss 0.1008 Accuracy 0.9601\n",
      "Epoch 3 Batch 4550 Loss 0.1007 Accuracy 0.9601\n",
      "Epoch 3 Batch 4600 Loss 0.1005 Accuracy 0.9602\n",
      "Epoch 3 Batch 4650 Loss 0.1004 Accuracy 0.9602\n",
      "Epoch 3 Batch 4700 Loss 0.1002 Accuracy 0.9603\n",
      "Epoch 3 Batch 4750 Loss 0.1001 Accuracy 0.9603\n",
      "Epoch 3 Batch 4800 Loss 0.1000 Accuracy 0.9604\n",
      "Epoch 3 Batch 4850 Loss 0.0998 Accuracy 0.9604\n",
      "Epoch 3 Batch 4900 Loss 0.0997 Accuracy 0.9605\n",
      "Epoch 3 Batch 4950 Loss 0.0996 Accuracy 0.9605\n",
      "Epoch 3 Batch 5000 Loss 0.0994 Accuracy 0.9606\n",
      "Epoch 3 Batch 5050 Loss 0.0993 Accuracy 0.9606\n",
      "Epoch 3 Batch 5100 Loss 0.0991 Accuracy 0.9606\n",
      "Epoch 3 Batch 5150 Loss 0.0990 Accuracy 0.9607\n",
      "Epoch 3 Batch 5200 Loss 0.0989 Accuracy 0.9607\n",
      "Epoch 3 Batch 5250 Loss 0.0988 Accuracy 0.9608\n",
      "Epoch 3 Batch 5300 Loss 0.0987 Accuracy 0.9608\n",
      "Epoch 3 Batch 5350 Loss 0.0985 Accuracy 0.9609\n",
      "Epoch 3 Batch 5400 Loss 0.0984 Accuracy 0.9609\n",
      "Epoch 3 Batch 5450 Loss 0.0983 Accuracy 0.9609\n",
      "Epoch 3 Batch 5500 Loss 0.0981 Accuracy 0.9610\n",
      "Epoch 3 Batch 5550 Loss 0.0980 Accuracy 0.9610\n",
      "Epoch 3 Batch 5600 Loss 0.0979 Accuracy 0.9611\n",
      "Epoch 3 Batch 5650 Loss 0.0978 Accuracy 0.9611\n",
      "Epoch 3 Batch 5700 Loss 0.0977 Accuracy 0.9612\n",
      "Epoch 3 Batch 5750 Loss 0.0975 Accuracy 0.9612\n",
      "Epoch 3 Batch 5800 Loss 0.0974 Accuracy 0.9612\n",
      "Epoch 3 Batch 5850 Loss 0.0973 Accuracy 0.9613\n",
      "Epoch 3 Batch 5900 Loss 0.0972 Accuracy 0.9613\n",
      "Epoch 3 Batch 5950 Loss 0.0970 Accuracy 0.9614\n",
      "Epoch 3 Batch 6000 Loss 0.0969 Accuracy 0.9614\n",
      "Epoch 3 Batch 6050 Loss 0.0967 Accuracy 0.9615\n",
      "Epoch 3 Batch 6100 Loss 0.0966 Accuracy 0.9615\n",
      "Epoch 3 Batch 6150 Loss 0.0964 Accuracy 0.9616\n",
      "Epoch 3 Batch 6200 Loss 0.0963 Accuracy 0.9616\n",
      "Epoch 3 Loss 0.0962 Accuracy 0.9617\n",
      "Time taken for 1 epoch: 612.91 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0825 Accuracy 0.9676\n",
      "Epoch 4 Batch 50 Loss 0.0776 Accuracy 0.9680\n",
      "Epoch 4 Batch 100 Loss 0.0808 Accuracy 0.9671\n",
      "Epoch 4 Batch 150 Loss 0.0816 Accuracy 0.9667\n",
      "Epoch 4 Batch 200 Loss 0.0826 Accuracy 0.9664\n",
      "Epoch 4 Batch 250 Loss 0.0823 Accuracy 0.9665\n",
      "Epoch 4 Batch 300 Loss 0.0824 Accuracy 0.9664\n",
      "Epoch 4 Batch 350 Loss 0.0814 Accuracy 0.9669\n",
      "Epoch 4 Batch 400 Loss 0.0812 Accuracy 0.9669\n",
      "Epoch 4 Batch 450 Loss 0.0809 Accuracy 0.9669\n",
      "Epoch 4 Batch 500 Loss 0.0807 Accuracy 0.9669\n",
      "Epoch 4 Batch 550 Loss 0.0802 Accuracy 0.9671\n",
      "Epoch 4 Batch 600 Loss 0.0803 Accuracy 0.9670\n",
      "Epoch 4 Batch 650 Loss 0.0802 Accuracy 0.9671\n",
      "Epoch 4 Batch 700 Loss 0.0803 Accuracy 0.9671\n",
      "Epoch 4 Batch 750 Loss 0.0801 Accuracy 0.9671\n",
      "Epoch 4 Batch 800 Loss 0.0800 Accuracy 0.9672\n",
      "Epoch 4 Batch 850 Loss 0.0801 Accuracy 0.9671\n",
      "Epoch 4 Batch 900 Loss 0.0800 Accuracy 0.9671\n",
      "Epoch 4 Batch 950 Loss 0.0797 Accuracy 0.9672\n",
      "Epoch 4 Batch 1000 Loss 0.0796 Accuracy 0.9673\n",
      "Epoch 4 Batch 1050 Loss 0.0795 Accuracy 0.9673\n",
      "Epoch 4 Batch 1100 Loss 0.0794 Accuracy 0.9673\n",
      "Epoch 4 Batch 1150 Loss 0.0792 Accuracy 0.9674\n",
      "Epoch 4 Batch 1200 Loss 0.0793 Accuracy 0.9673\n",
      "Epoch 4 Batch 1250 Loss 0.0793 Accuracy 0.9674\n",
      "Epoch 4 Batch 1300 Loss 0.0791 Accuracy 0.9674\n",
      "Epoch 4 Batch 1350 Loss 0.0790 Accuracy 0.9674\n",
      "Epoch 4 Batch 1400 Loss 0.0790 Accuracy 0.9674\n",
      "Epoch 4 Batch 1450 Loss 0.0789 Accuracy 0.9675\n",
      "Epoch 4 Batch 1500 Loss 0.0788 Accuracy 0.9675\n",
      "Epoch 4 Batch 1550 Loss 0.0787 Accuracy 0.9676\n",
      "Epoch 4 Batch 1600 Loss 0.0786 Accuracy 0.9676\n",
      "Epoch 4 Batch 1650 Loss 0.0786 Accuracy 0.9676\n",
      "Epoch 4 Batch 1700 Loss 0.0785 Accuracy 0.9676\n",
      "Epoch 4 Batch 1750 Loss 0.0786 Accuracy 0.9676\n",
      "Epoch 4 Batch 1800 Loss 0.0785 Accuracy 0.9676\n",
      "Epoch 4 Batch 1850 Loss 0.0785 Accuracy 0.9677\n",
      "Epoch 4 Batch 1900 Loss 0.0785 Accuracy 0.9677\n",
      "Epoch 4 Batch 1950 Loss 0.0783 Accuracy 0.9677\n",
      "Epoch 4 Batch 2000 Loss 0.0783 Accuracy 0.9677\n",
      "Epoch 4 Batch 2050 Loss 0.0782 Accuracy 0.9678\n",
      "Epoch 4 Batch 2100 Loss 0.0781 Accuracy 0.9678\n",
      "Epoch 4 Batch 2150 Loss 0.0780 Accuracy 0.9678\n",
      "Epoch 4 Batch 2200 Loss 0.0779 Accuracy 0.9679\n",
      "Epoch 4 Batch 2250 Loss 0.0778 Accuracy 0.9679\n",
      "Epoch 4 Batch 2300 Loss 0.0778 Accuracy 0.9679\n",
      "Epoch 4 Batch 2350 Loss 0.0777 Accuracy 0.9679\n",
      "Epoch 4 Batch 2400 Loss 0.0776 Accuracy 0.9680\n",
      "Epoch 4 Batch 2450 Loss 0.0775 Accuracy 0.9680\n",
      "Epoch 4 Batch 2500 Loss 0.0774 Accuracy 0.9680\n",
      "Epoch 4 Batch 2550 Loss 0.0774 Accuracy 0.9680\n",
      "Epoch 4 Batch 2600 Loss 0.0773 Accuracy 0.9680\n",
      "Epoch 4 Batch 2650 Loss 0.0772 Accuracy 0.9681\n",
      "Epoch 4 Batch 2700 Loss 0.0771 Accuracy 0.9681\n",
      "Epoch 4 Batch 2750 Loss 0.0770 Accuracy 0.9681\n",
      "Epoch 4 Batch 2800 Loss 0.0769 Accuracy 0.9682\n",
      "Epoch 4 Batch 2850 Loss 0.0769 Accuracy 0.9682\n",
      "Epoch 4 Batch 2900 Loss 0.0768 Accuracy 0.9682\n",
      "Epoch 4 Batch 2950 Loss 0.0767 Accuracy 0.9683\n",
      "Epoch 4 Batch 3000 Loss 0.0767 Accuracy 0.9683\n",
      "Epoch 4 Batch 3050 Loss 0.0766 Accuracy 0.9683\n",
      "Epoch 4 Batch 3100 Loss 0.0764 Accuracy 0.9684\n",
      "Epoch 4 Batch 3150 Loss 0.0764 Accuracy 0.9684\n",
      "Epoch 4 Batch 3200 Loss 0.0763 Accuracy 0.9684\n",
      "Epoch 4 Batch 3250 Loss 0.0763 Accuracy 0.9684\n",
      "Epoch 4 Batch 3300 Loss 0.0762 Accuracy 0.9684\n",
      "Epoch 4 Batch 3350 Loss 0.0762 Accuracy 0.9685\n",
      "Epoch 4 Batch 3400 Loss 0.0761 Accuracy 0.9685\n",
      "Epoch 4 Batch 3450 Loss 0.0761 Accuracy 0.9685\n",
      "Epoch 4 Batch 3500 Loss 0.0760 Accuracy 0.9685\n",
      "Epoch 4 Batch 3550 Loss 0.0759 Accuracy 0.9685\n",
      "Epoch 4 Batch 3600 Loss 0.0759 Accuracy 0.9686\n",
      "Epoch 4 Batch 3650 Loss 0.0758 Accuracy 0.9686\n",
      "Epoch 4 Batch 3700 Loss 0.0757 Accuracy 0.9686\n",
      "Epoch 4 Batch 3750 Loss 0.0756 Accuracy 0.9686\n",
      "Epoch 4 Batch 3800 Loss 0.0756 Accuracy 0.9687\n",
      "Epoch 4 Batch 3850 Loss 0.0755 Accuracy 0.9687\n",
      "Epoch 4 Batch 3900 Loss 0.0754 Accuracy 0.9687\n",
      "Epoch 4 Batch 3950 Loss 0.0754 Accuracy 0.9687\n",
      "Epoch 4 Batch 4000 Loss 0.0753 Accuracy 0.9687\n",
      "Epoch 4 Batch 4050 Loss 0.0753 Accuracy 0.9688\n",
      "Epoch 4 Batch 4100 Loss 0.0752 Accuracy 0.9688\n",
      "Epoch 4 Batch 4150 Loss 0.0751 Accuracy 0.9688\n",
      "Epoch 4 Batch 4200 Loss 0.0750 Accuracy 0.9688\n",
      "Epoch 4 Batch 4250 Loss 0.0750 Accuracy 0.9689\n",
      "Epoch 4 Batch 4300 Loss 0.0749 Accuracy 0.9689\n",
      "Epoch 4 Batch 4350 Loss 0.0748 Accuracy 0.9689\n",
      "Epoch 4 Batch 4400 Loss 0.0748 Accuracy 0.9689\n",
      "Epoch 4 Batch 4450 Loss 0.0747 Accuracy 0.9689\n",
      "Epoch 4 Batch 4500 Loss 0.0747 Accuracy 0.9690\n",
      "Epoch 4 Batch 4550 Loss 0.0746 Accuracy 0.9690\n",
      "Epoch 4 Batch 4600 Loss 0.0746 Accuracy 0.9690\n",
      "Epoch 4 Batch 4650 Loss 0.0745 Accuracy 0.9690\n",
      "Epoch 4 Batch 4700 Loss 0.0744 Accuracy 0.9690\n",
      "Epoch 4 Batch 4750 Loss 0.0744 Accuracy 0.9691\n",
      "Epoch 4 Batch 4800 Loss 0.0743 Accuracy 0.9691\n",
      "Epoch 4 Batch 4850 Loss 0.0742 Accuracy 0.9691\n",
      "Epoch 4 Batch 4900 Loss 0.0742 Accuracy 0.9691\n",
      "Epoch 4 Batch 4950 Loss 0.0741 Accuracy 0.9692\n",
      "Epoch 4 Batch 5000 Loss 0.0741 Accuracy 0.9692\n",
      "Epoch 4 Batch 5050 Loss 0.0740 Accuracy 0.9692\n",
      "Epoch 4 Batch 5100 Loss 0.0740 Accuracy 0.9692\n",
      "Epoch 4 Batch 5150 Loss 0.0739 Accuracy 0.9692\n",
      "Epoch 4 Batch 5200 Loss 0.0739 Accuracy 0.9692\n",
      "Epoch 4 Batch 5250 Loss 0.0738 Accuracy 0.9693\n",
      "Epoch 4 Batch 5300 Loss 0.0737 Accuracy 0.9693\n",
      "Epoch 4 Batch 5350 Loss 0.0737 Accuracy 0.9693\n",
      "Epoch 4 Batch 5400 Loss 0.0736 Accuracy 0.9693\n",
      "Epoch 4 Batch 5450 Loss 0.0736 Accuracy 0.9693\n",
      "Epoch 4 Batch 5500 Loss 0.0735 Accuracy 0.9694\n",
      "Epoch 4 Batch 5550 Loss 0.0734 Accuracy 0.9694\n",
      "Epoch 4 Batch 5600 Loss 0.0734 Accuracy 0.9694\n",
      "Epoch 4 Batch 5650 Loss 0.0733 Accuracy 0.9694\n",
      "Epoch 4 Batch 5700 Loss 0.0732 Accuracy 0.9695\n",
      "Epoch 4 Batch 5750 Loss 0.0732 Accuracy 0.9695\n",
      "Epoch 4 Batch 5800 Loss 0.0731 Accuracy 0.9695\n",
      "Epoch 4 Batch 5850 Loss 0.0731 Accuracy 0.9695\n",
      "Epoch 4 Batch 5900 Loss 0.0730 Accuracy 0.9695\n",
      "Epoch 4 Batch 5950 Loss 0.0729 Accuracy 0.9696\n",
      "Epoch 4 Batch 6000 Loss 0.0728 Accuracy 0.9696\n",
      "Epoch 4 Batch 6050 Loss 0.0728 Accuracy 0.9696\n",
      "Epoch 4 Batch 6100 Loss 0.0727 Accuracy 0.9696\n",
      "Epoch 4 Batch 6150 Loss 0.0726 Accuracy 0.9697\n",
      "Epoch 4 Batch 6200 Loss 0.0725 Accuracy 0.9697\n",
      "Epoch 4 Loss 0.0725 Accuracy 0.9697\n",
      "Time taken for 1 epoch: 612.00 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0591 Accuracy 0.9739\n",
      "Epoch 5 Batch 50 Loss 0.0635 Accuracy 0.9728\n",
      "Epoch 5 Batch 100 Loss 0.0652 Accuracy 0.9722\n",
      "Epoch 5 Batch 150 Loss 0.0654 Accuracy 0.9721\n",
      "Epoch 5 Batch 200 Loss 0.0667 Accuracy 0.9717\n",
      "Epoch 5 Batch 250 Loss 0.0666 Accuracy 0.9716\n",
      "Epoch 5 Batch 300 Loss 0.0662 Accuracy 0.9717\n",
      "Epoch 5 Batch 350 Loss 0.0656 Accuracy 0.9720\n",
      "Epoch 5 Batch 400 Loss 0.0656 Accuracy 0.9719\n",
      "Epoch 5 Batch 450 Loss 0.0654 Accuracy 0.9720\n",
      "Epoch 5 Batch 500 Loss 0.0656 Accuracy 0.9719\n",
      "Epoch 5 Batch 550 Loss 0.0649 Accuracy 0.9721\n",
      "Epoch 5 Batch 600 Loss 0.0649 Accuracy 0.9721\n",
      "Epoch 5 Batch 650 Loss 0.0649 Accuracy 0.9721\n",
      "Epoch 5 Batch 700 Loss 0.0648 Accuracy 0.9721\n",
      "Epoch 5 Batch 750 Loss 0.0647 Accuracy 0.9721\n",
      "Epoch 5 Batch 800 Loss 0.0647 Accuracy 0.9721\n",
      "Epoch 5 Batch 850 Loss 0.0649 Accuracy 0.9721\n",
      "Epoch 5 Batch 900 Loss 0.0647 Accuracy 0.9721\n",
      "Epoch 5 Batch 950 Loss 0.0646 Accuracy 0.9722\n",
      "Epoch 5 Batch 1000 Loss 0.0646 Accuracy 0.9722\n",
      "Epoch 5 Batch 1050 Loss 0.0646 Accuracy 0.9722\n",
      "Epoch 5 Batch 1100 Loss 0.0644 Accuracy 0.9722\n",
      "Epoch 5 Batch 1150 Loss 0.0643 Accuracy 0.9723\n",
      "Epoch 5 Batch 1200 Loss 0.0643 Accuracy 0.9723\n",
      "Epoch 5 Batch 1250 Loss 0.0643 Accuracy 0.9723\n",
      "Epoch 5 Batch 1300 Loss 0.0642 Accuracy 0.9724\n",
      "Epoch 5 Batch 1350 Loss 0.0642 Accuracy 0.9724\n",
      "Epoch 5 Batch 1400 Loss 0.0643 Accuracy 0.9723\n",
      "Epoch 5 Batch 1450 Loss 0.0643 Accuracy 0.9724\n",
      "Epoch 5 Batch 1500 Loss 0.0642 Accuracy 0.9724\n",
      "Epoch 5 Batch 1550 Loss 0.0641 Accuracy 0.9724\n",
      "Epoch 5 Batch 1600 Loss 0.0641 Accuracy 0.9724\n",
      "Epoch 5 Batch 1650 Loss 0.0640 Accuracy 0.9724\n",
      "Epoch 5 Batch 1700 Loss 0.0639 Accuracy 0.9725\n",
      "Epoch 5 Batch 1750 Loss 0.0640 Accuracy 0.9725\n",
      "Epoch 5 Batch 1800 Loss 0.0640 Accuracy 0.9725\n",
      "Epoch 5 Batch 1850 Loss 0.0640 Accuracy 0.9725\n",
      "Epoch 5 Batch 1900 Loss 0.0639 Accuracy 0.9725\n",
      "Epoch 5 Batch 1950 Loss 0.0639 Accuracy 0.9725\n",
      "Epoch 5 Batch 2000 Loss 0.0639 Accuracy 0.9725\n",
      "Epoch 5 Batch 2050 Loss 0.0638 Accuracy 0.9726\n",
      "Epoch 5 Batch 2100 Loss 0.0637 Accuracy 0.9726\n",
      "Epoch 5 Batch 2150 Loss 0.0637 Accuracy 0.9726\n",
      "Epoch 5 Batch 2200 Loss 0.0636 Accuracy 0.9726\n",
      "Epoch 5 Batch 2250 Loss 0.0636 Accuracy 0.9727\n",
      "Epoch 5 Batch 2300 Loss 0.0636 Accuracy 0.9727\n",
      "Epoch 5 Batch 2350 Loss 0.0636 Accuracy 0.9727\n",
      "Epoch 5 Batch 2400 Loss 0.0635 Accuracy 0.9727\n",
      "Epoch 5 Batch 2450 Loss 0.0635 Accuracy 0.9727\n",
      "Epoch 5 Batch 2500 Loss 0.0634 Accuracy 0.9727\n",
      "Epoch 5 Batch 2550 Loss 0.0633 Accuracy 0.9728\n",
      "Epoch 5 Batch 2600 Loss 0.0633 Accuracy 0.9728\n",
      "Epoch 5 Batch 2650 Loss 0.0632 Accuracy 0.9728\n",
      "Epoch 5 Batch 2700 Loss 0.0631 Accuracy 0.9728\n",
      "Epoch 5 Batch 2750 Loss 0.0631 Accuracy 0.9728\n",
      "Epoch 5 Batch 2800 Loss 0.0630 Accuracy 0.9728\n",
      "Epoch 5 Batch 2850 Loss 0.0630 Accuracy 0.9729\n",
      "Epoch 5 Batch 2900 Loss 0.0629 Accuracy 0.9729\n",
      "Epoch 5 Batch 2950 Loss 0.0628 Accuracy 0.9729\n",
      "Epoch 5 Batch 3000 Loss 0.0628 Accuracy 0.9729\n",
      "Epoch 5 Batch 3050 Loss 0.0627 Accuracy 0.9729\n",
      "Epoch 5 Batch 3100 Loss 0.0626 Accuracy 0.9730\n",
      "Epoch 5 Batch 3150 Loss 0.0626 Accuracy 0.9730\n",
      "Epoch 5 Batch 3200 Loss 0.0625 Accuracy 0.9730\n",
      "Epoch 5 Batch 3250 Loss 0.0625 Accuracy 0.9730\n",
      "Epoch 5 Batch 3300 Loss 0.0624 Accuracy 0.9730\n",
      "Epoch 5 Batch 3350 Loss 0.0624 Accuracy 0.9730\n",
      "Epoch 5 Batch 3400 Loss 0.0624 Accuracy 0.9730\n",
      "Epoch 5 Batch 3450 Loss 0.0624 Accuracy 0.9730\n",
      "Epoch 5 Batch 3500 Loss 0.0623 Accuracy 0.9731\n",
      "Epoch 5 Batch 3550 Loss 0.0624 Accuracy 0.9731\n",
      "Epoch 5 Batch 3600 Loss 0.0623 Accuracy 0.9731\n",
      "Epoch 5 Batch 3650 Loss 0.0622 Accuracy 0.9731\n",
      "Epoch 5 Batch 3700 Loss 0.0622 Accuracy 0.9731\n",
      "Epoch 5 Batch 3750 Loss 0.0622 Accuracy 0.9731\n",
      "Epoch 5 Batch 3800 Loss 0.0621 Accuracy 0.9731\n",
      "Epoch 5 Batch 3850 Loss 0.0620 Accuracy 0.9732\n",
      "Epoch 5 Batch 3900 Loss 0.0620 Accuracy 0.9732\n",
      "Epoch 5 Batch 3950 Loss 0.0620 Accuracy 0.9732\n",
      "Epoch 5 Batch 4000 Loss 0.0620 Accuracy 0.9732\n",
      "Epoch 5 Batch 4050 Loss 0.0619 Accuracy 0.9732\n",
      "Epoch 5 Batch 4100 Loss 0.0619 Accuracy 0.9732\n",
      "Epoch 5 Batch 4150 Loss 0.0618 Accuracy 0.9732\n",
      "Epoch 5 Batch 4200 Loss 0.0618 Accuracy 0.9732\n",
      "Epoch 5 Batch 4250 Loss 0.0617 Accuracy 0.9732\n",
      "Epoch 5 Batch 4300 Loss 0.0617 Accuracy 0.9732\n",
      "Epoch 5 Batch 4350 Loss 0.0616 Accuracy 0.9733\n",
      "Epoch 5 Batch 4400 Loss 0.0616 Accuracy 0.9733\n",
      "Epoch 5 Batch 4450 Loss 0.0616 Accuracy 0.9733\n",
      "Epoch 5 Batch 4500 Loss 0.0616 Accuracy 0.9733\n",
      "Epoch 5 Batch 4550 Loss 0.0615 Accuracy 0.9733\n",
      "Epoch 5 Batch 4600 Loss 0.0615 Accuracy 0.9733\n",
      "Epoch 5 Batch 4650 Loss 0.0615 Accuracy 0.9733\n",
      "Epoch 5 Batch 4700 Loss 0.0614 Accuracy 0.9733\n",
      "Epoch 5 Batch 4750 Loss 0.0614 Accuracy 0.9733\n",
      "Epoch 5 Batch 4800 Loss 0.0613 Accuracy 0.9734\n",
      "Epoch 5 Batch 4850 Loss 0.0613 Accuracy 0.9734\n",
      "Epoch 5 Batch 4900 Loss 0.0613 Accuracy 0.9734\n",
      "Epoch 5 Batch 4950 Loss 0.0612 Accuracy 0.9734\n",
      "Epoch 5 Batch 5000 Loss 0.0612 Accuracy 0.9734\n",
      "Epoch 5 Batch 5050 Loss 0.0612 Accuracy 0.9734\n",
      "Epoch 5 Batch 5100 Loss 0.0611 Accuracy 0.9734\n",
      "Epoch 5 Batch 5150 Loss 0.0611 Accuracy 0.9735\n",
      "Epoch 5 Batch 5200 Loss 0.0611 Accuracy 0.9735\n",
      "Epoch 5 Batch 5250 Loss 0.0610 Accuracy 0.9735\n",
      "Epoch 5 Batch 5300 Loss 0.0610 Accuracy 0.9735\n",
      "Epoch 5 Batch 5350 Loss 0.0610 Accuracy 0.9735\n",
      "Epoch 5 Batch 5400 Loss 0.0609 Accuracy 0.9735\n",
      "Epoch 5 Batch 5450 Loss 0.0609 Accuracy 0.9735\n",
      "Epoch 5 Batch 5500 Loss 0.0609 Accuracy 0.9735\n",
      "Epoch 5 Batch 5550 Loss 0.0608 Accuracy 0.9735\n",
      "Epoch 5 Batch 5600 Loss 0.0608 Accuracy 0.9736\n",
      "Epoch 5 Batch 5650 Loss 0.0608 Accuracy 0.9736\n",
      "Epoch 5 Batch 5700 Loss 0.0607 Accuracy 0.9736\n",
      "Epoch 5 Batch 5750 Loss 0.0607 Accuracy 0.9736\n",
      "Epoch 5 Batch 5800 Loss 0.0606 Accuracy 0.9736\n",
      "Epoch 5 Batch 5850 Loss 0.0606 Accuracy 0.9736\n",
      "Epoch 5 Batch 5900 Loss 0.0605 Accuracy 0.9736\n",
      "Epoch 5 Batch 5950 Loss 0.0605 Accuracy 0.9736\n",
      "Epoch 5 Batch 6000 Loss 0.0604 Accuracy 0.9737\n",
      "Epoch 5 Batch 6050 Loss 0.0604 Accuracy 0.9737\n",
      "Epoch 5 Batch 6100 Loss 0.0603 Accuracy 0.9737\n",
      "Epoch 5 Batch 6150 Loss 0.0603 Accuracy 0.9737\n",
      "Epoch 5 Batch 6200 Loss 0.0602 Accuracy 0.9737\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
      "Epoch 5 Loss 0.0602 Accuracy 0.9737\n",
      "Time taken for 1 epoch: 596.58 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0530 Accuracy 0.9768\n",
      "Epoch 6 Batch 50 Loss 0.0533 Accuracy 0.9759\n",
      "Epoch 6 Batch 100 Loss 0.0550 Accuracy 0.9754\n",
      "Epoch 6 Batch 150 Loss 0.0558 Accuracy 0.9754\n",
      "Epoch 6 Batch 200 Loss 0.0568 Accuracy 0.9753\n",
      "Epoch 6 Batch 250 Loss 0.0565 Accuracy 0.9752\n",
      "Epoch 6 Batch 300 Loss 0.0565 Accuracy 0.9751\n",
      "Epoch 6 Batch 350 Loss 0.0560 Accuracy 0.9753\n",
      "Epoch 6 Batch 400 Loss 0.0559 Accuracy 0.9753\n",
      "Epoch 6 Batch 450 Loss 0.0558 Accuracy 0.9752\n",
      "Epoch 6 Batch 500 Loss 0.0558 Accuracy 0.9752\n",
      "Epoch 6 Batch 550 Loss 0.0553 Accuracy 0.9753\n",
      "Epoch 6 Batch 600 Loss 0.0556 Accuracy 0.9752\n",
      "Epoch 6 Batch 650 Loss 0.0555 Accuracy 0.9752\n",
      "Epoch 6 Batch 700 Loss 0.0556 Accuracy 0.9752\n",
      "Epoch 6 Batch 750 Loss 0.0555 Accuracy 0.9752\n",
      "Epoch 6 Batch 800 Loss 0.0554 Accuracy 0.9753\n",
      "Epoch 6 Batch 850 Loss 0.0555 Accuracy 0.9753\n",
      "Epoch 6 Batch 900 Loss 0.0554 Accuracy 0.9753\n",
      "Epoch 6 Batch 950 Loss 0.0554 Accuracy 0.9753\n",
      "Epoch 6 Batch 1000 Loss 0.0554 Accuracy 0.9753\n",
      "Epoch 6 Batch 1050 Loss 0.0554 Accuracy 0.9753\n",
      "Epoch 6 Batch 1100 Loss 0.0553 Accuracy 0.9753\n",
      "Epoch 6 Batch 1150 Loss 0.0553 Accuracy 0.9753\n",
      "Epoch 6 Batch 1200 Loss 0.0553 Accuracy 0.9753\n",
      "Epoch 6 Batch 1250 Loss 0.0553 Accuracy 0.9753\n",
      "Epoch 6 Batch 1300 Loss 0.0552 Accuracy 0.9753\n",
      "Epoch 6 Batch 1350 Loss 0.0552 Accuracy 0.9753\n",
      "Epoch 6 Batch 1400 Loss 0.0552 Accuracy 0.9753\n",
      "Epoch 6 Batch 1450 Loss 0.0552 Accuracy 0.9753\n",
      "Epoch 6 Batch 1500 Loss 0.0552 Accuracy 0.9753\n",
      "Epoch 6 Batch 1550 Loss 0.0551 Accuracy 0.9754\n",
      "Epoch 6 Batch 1600 Loss 0.0551 Accuracy 0.9754\n",
      "Epoch 6 Batch 1650 Loss 0.0550 Accuracy 0.9754\n",
      "Epoch 6 Batch 1700 Loss 0.0550 Accuracy 0.9754\n",
      "Epoch 6 Batch 1750 Loss 0.0551 Accuracy 0.9754\n",
      "Epoch 6 Batch 1800 Loss 0.0551 Accuracy 0.9754\n",
      "Epoch 6 Batch 1850 Loss 0.0552 Accuracy 0.9754\n",
      "Epoch 6 Batch 1900 Loss 0.0551 Accuracy 0.9754\n",
      "Epoch 6 Batch 1950 Loss 0.0551 Accuracy 0.9754\n",
      "Epoch 6 Batch 2000 Loss 0.0551 Accuracy 0.9754\n",
      "Epoch 6 Batch 2050 Loss 0.0550 Accuracy 0.9754\n",
      "Epoch 6 Batch 2100 Loss 0.0550 Accuracy 0.9754\n",
      "Epoch 6 Batch 2150 Loss 0.0549 Accuracy 0.9755\n",
      "Epoch 6 Batch 2200 Loss 0.0549 Accuracy 0.9755\n",
      "Epoch 6 Batch 2250 Loss 0.0549 Accuracy 0.9755\n",
      "Epoch 6 Batch 2300 Loss 0.0548 Accuracy 0.9755\n",
      "Epoch 6 Batch 2350 Loss 0.0549 Accuracy 0.9755\n",
      "Epoch 6 Batch 2400 Loss 0.0548 Accuracy 0.9755\n",
      "Epoch 6 Batch 2450 Loss 0.0547 Accuracy 0.9755\n",
      "Epoch 6 Batch 2500 Loss 0.0546 Accuracy 0.9756\n",
      "Epoch 6 Batch 2550 Loss 0.0546 Accuracy 0.9756\n",
      "Epoch 6 Batch 2600 Loss 0.0546 Accuracy 0.9756\n",
      "Epoch 6 Batch 2650 Loss 0.0545 Accuracy 0.9756\n",
      "Epoch 6 Batch 2700 Loss 0.0545 Accuracy 0.9756\n",
      "Epoch 6 Batch 2750 Loss 0.0545 Accuracy 0.9756\n",
      "Epoch 6 Batch 2800 Loss 0.0544 Accuracy 0.9757\n",
      "Epoch 6 Batch 2850 Loss 0.0544 Accuracy 0.9757\n",
      "Epoch 6 Batch 2900 Loss 0.0543 Accuracy 0.9757\n",
      "Epoch 6 Batch 2950 Loss 0.0543 Accuracy 0.9757\n",
      "Epoch 6 Batch 3000 Loss 0.0543 Accuracy 0.9757\n",
      "Epoch 6 Batch 3050 Loss 0.0543 Accuracy 0.9757\n",
      "Epoch 6 Batch 3100 Loss 0.0542 Accuracy 0.9757\n",
      "Epoch 6 Batch 3150 Loss 0.0542 Accuracy 0.9757\n",
      "Epoch 6 Batch 3200 Loss 0.0542 Accuracy 0.9757\n",
      "Epoch 6 Batch 3250 Loss 0.0542 Accuracy 0.9757\n",
      "Epoch 6 Batch 3300 Loss 0.0541 Accuracy 0.9758\n",
      "Epoch 6 Batch 3350 Loss 0.0541 Accuracy 0.9758\n",
      "Epoch 6 Batch 3400 Loss 0.0541 Accuracy 0.9758\n",
      "Epoch 6 Batch 3450 Loss 0.0541 Accuracy 0.9758\n",
      "Epoch 6 Batch 3500 Loss 0.0540 Accuracy 0.9758\n",
      "Epoch 6 Batch 3550 Loss 0.0541 Accuracy 0.9758\n",
      "Epoch 6 Batch 3600 Loss 0.0541 Accuracy 0.9758\n",
      "Epoch 6 Batch 3650 Loss 0.0541 Accuracy 0.9758\n",
      "Epoch 6 Batch 3700 Loss 0.0540 Accuracy 0.9758\n",
      "Epoch 6 Batch 3750 Loss 0.0540 Accuracy 0.9758\n",
      "Epoch 6 Batch 3800 Loss 0.0540 Accuracy 0.9758\n",
      "Epoch 6 Batch 3850 Loss 0.0539 Accuracy 0.9758\n",
      "Epoch 6 Batch 3900 Loss 0.0539 Accuracy 0.9758\n",
      "Epoch 6 Batch 3950 Loss 0.0539 Accuracy 0.9758\n",
      "Epoch 6 Batch 4000 Loss 0.0539 Accuracy 0.9758\n",
      "Epoch 6 Batch 4050 Loss 0.0539 Accuracy 0.9758\n",
      "Epoch 6 Batch 4100 Loss 0.0539 Accuracy 0.9758\n",
      "Epoch 6 Batch 4150 Loss 0.0538 Accuracy 0.9758\n",
      "Epoch 6 Batch 4200 Loss 0.0538 Accuracy 0.9759\n",
      "Epoch 6 Batch 4250 Loss 0.0538 Accuracy 0.9759\n",
      "Epoch 6 Batch 4300 Loss 0.0538 Accuracy 0.9759\n",
      "Epoch 6 Batch 4350 Loss 0.0538 Accuracy 0.9759\n",
      "Epoch 6 Batch 4400 Loss 0.0537 Accuracy 0.9759\n",
      "Epoch 6 Batch 4450 Loss 0.0537 Accuracy 0.9759\n",
      "Epoch 6 Batch 4500 Loss 0.0537 Accuracy 0.9759\n",
      "Epoch 6 Batch 4550 Loss 0.0537 Accuracy 0.9759\n",
      "Epoch 6 Batch 4600 Loss 0.0537 Accuracy 0.9759\n",
      "Epoch 6 Batch 4650 Loss 0.0537 Accuracy 0.9759\n",
      "Epoch 6 Batch 4700 Loss 0.0536 Accuracy 0.9759\n",
      "Epoch 6 Batch 4750 Loss 0.0536 Accuracy 0.9759\n",
      "Epoch 6 Batch 4800 Loss 0.0536 Accuracy 0.9759\n",
      "Epoch 6 Batch 4850 Loss 0.0535 Accuracy 0.9759\n",
      "Epoch 6 Batch 4900 Loss 0.0535 Accuracy 0.9759\n",
      "Epoch 6 Batch 4950 Loss 0.0535 Accuracy 0.9760\n",
      "Epoch 6 Batch 5000 Loss 0.0535 Accuracy 0.9760\n",
      "Epoch 6 Batch 5050 Loss 0.0534 Accuracy 0.9760\n",
      "Epoch 6 Batch 5100 Loss 0.0534 Accuracy 0.9760\n",
      "Epoch 6 Batch 5150 Loss 0.0533 Accuracy 0.9760\n",
      "Epoch 6 Batch 5200 Loss 0.0534 Accuracy 0.9760\n",
      "Epoch 6 Batch 5250 Loss 0.0533 Accuracy 0.9760\n",
      "Epoch 6 Batch 5300 Loss 0.0533 Accuracy 0.9760\n",
      "Epoch 6 Batch 5350 Loss 0.0533 Accuracy 0.9760\n",
      "Epoch 6 Batch 5400 Loss 0.0533 Accuracy 0.9760\n",
      "Epoch 6 Batch 5450 Loss 0.0532 Accuracy 0.9760\n",
      "Epoch 6 Batch 5500 Loss 0.0532 Accuracy 0.9761\n",
      "Epoch 6 Batch 5550 Loss 0.0532 Accuracy 0.9761\n",
      "Epoch 6 Batch 5600 Loss 0.0532 Accuracy 0.9761\n",
      "Epoch 6 Batch 5650 Loss 0.0532 Accuracy 0.9761\n",
      "Epoch 6 Batch 5700 Loss 0.0531 Accuracy 0.9761\n",
      "Epoch 6 Batch 5750 Loss 0.0531 Accuracy 0.9761\n",
      "Epoch 6 Batch 5800 Loss 0.0531 Accuracy 0.9761\n",
      "Epoch 6 Batch 5850 Loss 0.0531 Accuracy 0.9761\n",
      "Epoch 6 Batch 5900 Loss 0.0531 Accuracy 0.9761\n",
      "Epoch 6 Batch 5950 Loss 0.0530 Accuracy 0.9761\n",
      "Epoch 6 Batch 6000 Loss 0.0530 Accuracy 0.9761\n",
      "Epoch 6 Batch 6050 Loss 0.0529 Accuracy 0.9762\n",
      "Epoch 6 Batch 6100 Loss 0.0529 Accuracy 0.9762\n",
      "Epoch 6 Batch 6150 Loss 0.0529 Accuracy 0.9762\n",
      "Epoch 6 Batch 6200 Loss 0.0529 Accuracy 0.9762\n",
      "Epoch 6 Loss 0.0528 Accuracy 0.9762\n",
      "Time taken for 1 epoch: 596.74 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0441 Accuracy 0.9753\n",
      "Epoch 7 Batch 50 Loss 0.0481 Accuracy 0.9776\n",
      "Epoch 7 Batch 100 Loss 0.0500 Accuracy 0.9770\n",
      "Epoch 7 Batch 150 Loss 0.0500 Accuracy 0.9771\n",
      "Epoch 7 Batch 200 Loss 0.0508 Accuracy 0.9770\n",
      "Epoch 7 Batch 250 Loss 0.0504 Accuracy 0.9771\n",
      "Epoch 7 Batch 300 Loss 0.0506 Accuracy 0.9771\n",
      "Epoch 7 Batch 350 Loss 0.0499 Accuracy 0.9773\n",
      "Epoch 7 Batch 400 Loss 0.0498 Accuracy 0.9773\n",
      "Epoch 7 Batch 450 Loss 0.0497 Accuracy 0.9773\n",
      "Epoch 7 Batch 500 Loss 0.0496 Accuracy 0.9773\n",
      "Epoch 7 Batch 550 Loss 0.0494 Accuracy 0.9774\n",
      "Epoch 7 Batch 600 Loss 0.0495 Accuracy 0.9773\n",
      "Epoch 7 Batch 650 Loss 0.0495 Accuracy 0.9773\n",
      "Epoch 7 Batch 700 Loss 0.0496 Accuracy 0.9772\n",
      "Epoch 7 Batch 750 Loss 0.0496 Accuracy 0.9773\n",
      "Epoch 7 Batch 800 Loss 0.0496 Accuracy 0.9772\n",
      "Epoch 7 Batch 850 Loss 0.0497 Accuracy 0.9772\n",
      "Epoch 7 Batch 900 Loss 0.0496 Accuracy 0.9772\n",
      "Epoch 7 Batch 950 Loss 0.0495 Accuracy 0.9772\n",
      "Epoch 7 Batch 1000 Loss 0.0496 Accuracy 0.9772\n",
      "Epoch 7 Batch 1050 Loss 0.0497 Accuracy 0.9772\n",
      "Epoch 7 Batch 1100 Loss 0.0496 Accuracy 0.9772\n",
      "Epoch 7 Batch 1150 Loss 0.0495 Accuracy 0.9772\n",
      "Epoch 7 Batch 1200 Loss 0.0496 Accuracy 0.9772\n",
      "Epoch 7 Batch 1250 Loss 0.0496 Accuracy 0.9772\n",
      "Epoch 7 Batch 1300 Loss 0.0496 Accuracy 0.9772\n",
      "Epoch 7 Batch 1350 Loss 0.0495 Accuracy 0.9773\n",
      "Epoch 7 Batch 1400 Loss 0.0495 Accuracy 0.9773\n",
      "Epoch 7 Batch 1450 Loss 0.0495 Accuracy 0.9773\n",
      "Epoch 7 Batch 1500 Loss 0.0494 Accuracy 0.9773\n",
      "Epoch 7 Batch 1550 Loss 0.0494 Accuracy 0.9773\n",
      "Epoch 7 Batch 1600 Loss 0.0494 Accuracy 0.9773\n",
      "Epoch 7 Batch 1650 Loss 0.0493 Accuracy 0.9773\n",
      "Epoch 7 Batch 1700 Loss 0.0493 Accuracy 0.9773\n",
      "Epoch 7 Batch 1750 Loss 0.0493 Accuracy 0.9773\n",
      "Epoch 7 Batch 1800 Loss 0.0494 Accuracy 0.9773\n",
      "Epoch 7 Batch 1850 Loss 0.0494 Accuracy 0.9774\n",
      "Epoch 7 Batch 1900 Loss 0.0493 Accuracy 0.9774\n",
      "Epoch 7 Batch 1950 Loss 0.0493 Accuracy 0.9774\n",
      "Epoch 7 Batch 2000 Loss 0.0493 Accuracy 0.9774\n",
      "Epoch 7 Batch 2050 Loss 0.0493 Accuracy 0.9774\n",
      "Epoch 7 Batch 2100 Loss 0.0493 Accuracy 0.9774\n",
      "Epoch 7 Batch 2150 Loss 0.0492 Accuracy 0.9774\n",
      "Epoch 7 Batch 2200 Loss 0.0492 Accuracy 0.9775\n",
      "Epoch 7 Batch 2250 Loss 0.0492 Accuracy 0.9775\n",
      "Epoch 7 Batch 2300 Loss 0.0491 Accuracy 0.9775\n",
      "Epoch 7 Batch 2350 Loss 0.0492 Accuracy 0.9774\n",
      "Epoch 7 Batch 2400 Loss 0.0491 Accuracy 0.9775\n",
      "Epoch 7 Batch 2450 Loss 0.0491 Accuracy 0.9775\n",
      "Epoch 7 Batch 2500 Loss 0.0490 Accuracy 0.9775\n",
      "Epoch 7 Batch 2550 Loss 0.0490 Accuracy 0.9775\n",
      "Epoch 7 Batch 2600 Loss 0.0490 Accuracy 0.9775\n",
      "Epoch 7 Batch 2650 Loss 0.0489 Accuracy 0.9776\n",
      "Epoch 7 Batch 2700 Loss 0.0489 Accuracy 0.9776\n",
      "Epoch 7 Batch 2750 Loss 0.0489 Accuracy 0.9775\n",
      "Epoch 7 Batch 2800 Loss 0.0488 Accuracy 0.9776\n",
      "Epoch 7 Batch 2850 Loss 0.0488 Accuracy 0.9776\n",
      "Epoch 7 Batch 2900 Loss 0.0488 Accuracy 0.9776\n",
      "Epoch 7 Batch 2950 Loss 0.0488 Accuracy 0.9776\n",
      "Epoch 7 Batch 3000 Loss 0.0488 Accuracy 0.9776\n",
      "Epoch 7 Batch 3050 Loss 0.0487 Accuracy 0.9776\n",
      "Epoch 7 Batch 3100 Loss 0.0487 Accuracy 0.9776\n",
      "Epoch 7 Batch 3150 Loss 0.0487 Accuracy 0.9776\n",
      "Epoch 7 Batch 3200 Loss 0.0487 Accuracy 0.9776\n",
      "Epoch 7 Batch 3250 Loss 0.0487 Accuracy 0.9776\n",
      "Epoch 7 Batch 3300 Loss 0.0486 Accuracy 0.9776\n",
      "Epoch 7 Batch 3350 Loss 0.0486 Accuracy 0.9776\n",
      "Epoch 7 Batch 3400 Loss 0.0486 Accuracy 0.9776\n",
      "Epoch 7 Batch 3450 Loss 0.0486 Accuracy 0.9776\n",
      "Epoch 7 Batch 3500 Loss 0.0486 Accuracy 0.9776\n",
      "Epoch 7 Batch 3550 Loss 0.0486 Accuracy 0.9776\n",
      "Epoch 7 Batch 3600 Loss 0.0487 Accuracy 0.9776\n",
      "Epoch 7 Batch 3650 Loss 0.0486 Accuracy 0.9776\n",
      "Epoch 7 Batch 3700 Loss 0.0486 Accuracy 0.9776\n",
      "Epoch 7 Batch 3750 Loss 0.0486 Accuracy 0.9776\n",
      "Epoch 7 Batch 3800 Loss 0.0486 Accuracy 0.9776\n",
      "Epoch 7 Batch 3850 Loss 0.0486 Accuracy 0.9777\n",
      "Epoch 7 Batch 3900 Loss 0.0486 Accuracy 0.9777\n",
      "Epoch 7 Batch 3950 Loss 0.0486 Accuracy 0.9777\n",
      "Epoch 7 Batch 4000 Loss 0.0486 Accuracy 0.9777\n",
      "Epoch 7 Batch 4050 Loss 0.0486 Accuracy 0.9777\n",
      "Epoch 7 Batch 4100 Loss 0.0486 Accuracy 0.9777\n",
      "Epoch 7 Batch 4150 Loss 0.0485 Accuracy 0.9777\n",
      "Epoch 7 Batch 4200 Loss 0.0485 Accuracy 0.9777\n",
      "Epoch 7 Batch 4250 Loss 0.0485 Accuracy 0.9777\n",
      "Epoch 7 Batch 4300 Loss 0.0485 Accuracy 0.9777\n",
      "Epoch 7 Batch 4350 Loss 0.0484 Accuracy 0.9777\n",
      "Epoch 7 Batch 4400 Loss 0.0485 Accuracy 0.9777\n",
      "Epoch 7 Batch 4450 Loss 0.0485 Accuracy 0.9777\n",
      "Epoch 7 Batch 4500 Loss 0.0485 Accuracy 0.9777\n",
      "Epoch 7 Batch 4550 Loss 0.0484 Accuracy 0.9777\n",
      "Epoch 7 Batch 4600 Loss 0.0484 Accuracy 0.9777\n",
      "Epoch 7 Batch 4650 Loss 0.0484 Accuracy 0.9777\n",
      "Epoch 7 Batch 4700 Loss 0.0484 Accuracy 0.9777\n",
      "Epoch 7 Batch 4750 Loss 0.0484 Accuracy 0.9777\n",
      "Epoch 7 Batch 4800 Loss 0.0484 Accuracy 0.9777\n",
      "Epoch 7 Batch 4850 Loss 0.0483 Accuracy 0.9777\n",
      "Epoch 7 Batch 4900 Loss 0.0483 Accuracy 0.9777\n",
      "Epoch 7 Batch 4950 Loss 0.0483 Accuracy 0.9777\n",
      "Epoch 7 Batch 5000 Loss 0.0483 Accuracy 0.9777\n",
      "Epoch 7 Batch 5050 Loss 0.0483 Accuracy 0.9777\n",
      "Epoch 7 Batch 5100 Loss 0.0483 Accuracy 0.9777\n",
      "Epoch 7 Batch 5150 Loss 0.0483 Accuracy 0.9777\n",
      "Epoch 7 Batch 5200 Loss 0.0483 Accuracy 0.9777\n",
      "Epoch 7 Batch 5250 Loss 0.0483 Accuracy 0.9777\n",
      "Epoch 7 Batch 5300 Loss 0.0483 Accuracy 0.9777\n",
      "Epoch 7 Batch 5350 Loss 0.0483 Accuracy 0.9777\n",
      "Epoch 7 Batch 5400 Loss 0.0482 Accuracy 0.9778\n",
      "Epoch 7 Batch 5450 Loss 0.0482 Accuracy 0.9778\n",
      "Epoch 7 Batch 5500 Loss 0.0482 Accuracy 0.9778\n",
      "Epoch 7 Batch 5550 Loss 0.0482 Accuracy 0.9778\n",
      "Epoch 7 Batch 5600 Loss 0.0481 Accuracy 0.9778\n",
      "Epoch 7 Batch 5650 Loss 0.0481 Accuracy 0.9778\n",
      "Epoch 7 Batch 5700 Loss 0.0481 Accuracy 0.9778\n",
      "Epoch 7 Batch 5750 Loss 0.0481 Accuracy 0.9778\n",
      "Epoch 7 Batch 5800 Loss 0.0481 Accuracy 0.9778\n",
      "Epoch 7 Batch 5850 Loss 0.0480 Accuracy 0.9778\n",
      "Epoch 7 Batch 5900 Loss 0.0480 Accuracy 0.9778\n",
      "Epoch 7 Batch 5950 Loss 0.0480 Accuracy 0.9779\n",
      "Epoch 7 Batch 6000 Loss 0.0479 Accuracy 0.9779\n",
      "Epoch 7 Batch 6050 Loss 0.0479 Accuracy 0.9779\n",
      "Epoch 7 Batch 6100 Loss 0.0479 Accuracy 0.9779\n",
      "Epoch 7 Batch 6150 Loss 0.0478 Accuracy 0.9779\n",
      "Epoch 7 Batch 6200 Loss 0.0478 Accuracy 0.9779\n",
      "Epoch 7 Loss 0.0478 Accuracy 0.9779\n",
      "Time taken for 1 epoch: 596.65 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0540 Accuracy 0.9787\n",
      "Epoch 8 Batch 50 Loss 0.0451 Accuracy 0.9788\n",
      "Epoch 8 Batch 100 Loss 0.0460 Accuracy 0.9786\n",
      "Epoch 8 Batch 150 Loss 0.0462 Accuracy 0.9786\n",
      "Epoch 8 Batch 200 Loss 0.0466 Accuracy 0.9786\n",
      "Epoch 8 Batch 250 Loss 0.0464 Accuracy 0.9785\n",
      "Epoch 8 Batch 300 Loss 0.0466 Accuracy 0.9785\n",
      "Epoch 8 Batch 350 Loss 0.0460 Accuracy 0.9787\n",
      "Epoch 8 Batch 400 Loss 0.0458 Accuracy 0.9787\n",
      "Epoch 8 Batch 450 Loss 0.0457 Accuracy 0.9786\n",
      "Epoch 8 Batch 500 Loss 0.0455 Accuracy 0.9787\n",
      "Epoch 8 Batch 550 Loss 0.0452 Accuracy 0.9787\n",
      "Epoch 8 Batch 600 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 650 Loss 0.0454 Accuracy 0.9786\n",
      "Epoch 8 Batch 700 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 750 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 800 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 850 Loss 0.0455 Accuracy 0.9786\n",
      "Epoch 8 Batch 900 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 950 Loss 0.0453 Accuracy 0.9787\n",
      "Epoch 8 Batch 1000 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 1050 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 1100 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 1150 Loss 0.0453 Accuracy 0.9787\n",
      "Epoch 8 Batch 1200 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 1250 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 1300 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 1350 Loss 0.0453 Accuracy 0.9787\n",
      "Epoch 8 Batch 1400 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 1450 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 1500 Loss 0.0454 Accuracy 0.9787\n",
      "Epoch 8 Batch 1550 Loss 0.0453 Accuracy 0.9787\n",
      "Epoch 8 Batch 1600 Loss 0.0453 Accuracy 0.9787\n",
      "Epoch 8 Batch 1650 Loss 0.0453 Accuracy 0.9787\n",
      "Epoch 8 Batch 1700 Loss 0.0453 Accuracy 0.9788\n",
      "Epoch 8 Batch 1750 Loss 0.0453 Accuracy 0.9787\n",
      "Epoch 8 Batch 1800 Loss 0.0453 Accuracy 0.9787\n",
      "Epoch 8 Batch 1850 Loss 0.0453 Accuracy 0.9787\n",
      "Epoch 8 Batch 1900 Loss 0.0453 Accuracy 0.9787\n",
      "Epoch 8 Batch 1950 Loss 0.0453 Accuracy 0.9788\n",
      "Epoch 8 Batch 2000 Loss 0.0453 Accuracy 0.9788\n",
      "Epoch 8 Batch 2050 Loss 0.0452 Accuracy 0.9788\n",
      "Epoch 8 Batch 2100 Loss 0.0452 Accuracy 0.9788\n",
      "Epoch 8 Batch 2150 Loss 0.0451 Accuracy 0.9788\n",
      "Epoch 8 Batch 2200 Loss 0.0451 Accuracy 0.9788\n",
      "Epoch 8 Batch 2250 Loss 0.0451 Accuracy 0.9788\n",
      "Epoch 8 Batch 2300 Loss 0.0451 Accuracy 0.9788\n",
      "Epoch 8 Batch 2350 Loss 0.0451 Accuracy 0.9788\n",
      "Epoch 8 Batch 2400 Loss 0.0450 Accuracy 0.9789\n",
      "Epoch 8 Batch 2450 Loss 0.0450 Accuracy 0.9789\n",
      "Epoch 8 Batch 2500 Loss 0.0450 Accuracy 0.9789\n",
      "Epoch 8 Batch 2550 Loss 0.0450 Accuracy 0.9789\n",
      "Epoch 8 Batch 2600 Loss 0.0450 Accuracy 0.9789\n",
      "Epoch 8 Batch 2650 Loss 0.0449 Accuracy 0.9789\n",
      "Epoch 8 Batch 2700 Loss 0.0449 Accuracy 0.9789\n",
      "Epoch 8 Batch 2750 Loss 0.0449 Accuracy 0.9789\n",
      "Epoch 8 Batch 2800 Loss 0.0449 Accuracy 0.9789\n",
      "Epoch 8 Batch 2850 Loss 0.0448 Accuracy 0.9789\n",
      "Epoch 8 Batch 2900 Loss 0.0448 Accuracy 0.9789\n",
      "Epoch 8 Batch 2950 Loss 0.0448 Accuracy 0.9789\n",
      "Epoch 8 Batch 3000 Loss 0.0448 Accuracy 0.9790\n",
      "Epoch 8 Batch 3050 Loss 0.0448 Accuracy 0.9790\n",
      "Epoch 8 Batch 3100 Loss 0.0448 Accuracy 0.9790\n",
      "Epoch 8 Batch 3150 Loss 0.0447 Accuracy 0.9790\n",
      "Epoch 8 Batch 3200 Loss 0.0447 Accuracy 0.9790\n",
      "Epoch 8 Batch 3250 Loss 0.0447 Accuracy 0.9790\n",
      "Epoch 8 Batch 3300 Loss 0.0447 Accuracy 0.9790\n",
      "Epoch 8 Batch 3350 Loss 0.0447 Accuracy 0.9790\n",
      "Epoch 8 Batch 3400 Loss 0.0447 Accuracy 0.9790\n",
      "Epoch 8 Batch 3450 Loss 0.0447 Accuracy 0.9790\n",
      "Epoch 8 Batch 3500 Loss 0.0447 Accuracy 0.9790\n",
      "Epoch 8 Batch 3550 Loss 0.0447 Accuracy 0.9790\n",
      "Epoch 8 Batch 3600 Loss 0.0447 Accuracy 0.9790\n",
      "Epoch 8 Batch 3650 Loss 0.0447 Accuracy 0.9790\n",
      "Epoch 8 Batch 3700 Loss 0.0446 Accuracy 0.9790\n",
      "Epoch 8 Batch 3750 Loss 0.0446 Accuracy 0.9790\n",
      "Epoch 8 Batch 3800 Loss 0.0446 Accuracy 0.9790\n",
      "Epoch 8 Batch 3850 Loss 0.0445 Accuracy 0.9790\n",
      "Epoch 8 Batch 3900 Loss 0.0445 Accuracy 0.9790\n",
      "Epoch 8 Batch 3950 Loss 0.0445 Accuracy 0.9790\n",
      "Epoch 8 Batch 4000 Loss 0.0445 Accuracy 0.9790\n",
      "Epoch 8 Batch 4050 Loss 0.0445 Accuracy 0.9790\n",
      "Epoch 8 Batch 4100 Loss 0.0445 Accuracy 0.9790\n",
      "Epoch 8 Batch 4150 Loss 0.0445 Accuracy 0.9790\n",
      "Epoch 8 Batch 4200 Loss 0.0445 Accuracy 0.9790\n",
      "Epoch 8 Batch 4250 Loss 0.0445 Accuracy 0.9790\n",
      "Epoch 8 Batch 4300 Loss 0.0445 Accuracy 0.9790\n",
      "Epoch 8 Batch 4350 Loss 0.0444 Accuracy 0.9790\n",
      "Epoch 8 Batch 4400 Loss 0.0444 Accuracy 0.9790\n",
      "Epoch 8 Batch 4450 Loss 0.0444 Accuracy 0.9791\n",
      "Epoch 8 Batch 4500 Loss 0.0444 Accuracy 0.9791\n",
      "Epoch 8 Batch 4550 Loss 0.0444 Accuracy 0.9791\n",
      "Epoch 8 Batch 4600 Loss 0.0444 Accuracy 0.9791\n",
      "Epoch 8 Batch 4650 Loss 0.0444 Accuracy 0.9791\n",
      "Epoch 8 Batch 4700 Loss 0.0444 Accuracy 0.9791\n",
      "Epoch 8 Batch 4750 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 4800 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 4850 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 4900 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 4950 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 5000 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 5050 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 5100 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 5150 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 5200 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 5250 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 5300 Loss 0.0443 Accuracy 0.9791\n",
      "Epoch 8 Batch 5350 Loss 0.0442 Accuracy 0.9791\n",
      "Epoch 8 Batch 5400 Loss 0.0442 Accuracy 0.9791\n",
      "Epoch 8 Batch 5450 Loss 0.0442 Accuracy 0.9791\n",
      "Epoch 8 Batch 5500 Loss 0.0442 Accuracy 0.9791\n",
      "Epoch 8 Batch 5550 Loss 0.0442 Accuracy 0.9791\n",
      "Epoch 8 Batch 5600 Loss 0.0442 Accuracy 0.9791\n",
      "Epoch 8 Batch 5650 Loss 0.0442 Accuracy 0.9791\n",
      "Epoch 8 Batch 5700 Loss 0.0441 Accuracy 0.9791\n",
      "Epoch 8 Batch 5750 Loss 0.0441 Accuracy 0.9791\n",
      "Epoch 8 Batch 5800 Loss 0.0441 Accuracy 0.9792\n",
      "Epoch 8 Batch 5850 Loss 0.0441 Accuracy 0.9792\n",
      "Epoch 8 Batch 5900 Loss 0.0441 Accuracy 0.9792\n",
      "Epoch 8 Batch 5950 Loss 0.0441 Accuracy 0.9792\n",
      "Epoch 8 Batch 6000 Loss 0.0440 Accuracy 0.9792\n",
      "Epoch 8 Batch 6050 Loss 0.0440 Accuracy 0.9792\n",
      "Epoch 8 Batch 6100 Loss 0.0440 Accuracy 0.9792\n",
      "Epoch 8 Batch 6150 Loss 0.0440 Accuracy 0.9792\n",
      "Epoch 8 Batch 6200 Loss 0.0440 Accuracy 0.9792\n",
      "Epoch 8 Loss 0.0440 Accuracy 0.9792\n",
      "Time taken for 1 epoch: 596.43 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0433 Accuracy 0.9802\n",
      "Epoch 9 Batch 50 Loss 0.0420 Accuracy 0.9795\n",
      "Epoch 9 Batch 100 Loss 0.0430 Accuracy 0.9792\n",
      "Epoch 9 Batch 150 Loss 0.0434 Accuracy 0.9793\n",
      "Epoch 9 Batch 200 Loss 0.0434 Accuracy 0.9795\n",
      "Epoch 9 Batch 250 Loss 0.0433 Accuracy 0.9796\n",
      "Epoch 9 Batch 300 Loss 0.0432 Accuracy 0.9796\n",
      "Epoch 9 Batch 350 Loss 0.0427 Accuracy 0.9798\n",
      "Epoch 9 Batch 400 Loss 0.0425 Accuracy 0.9799\n",
      "Epoch 9 Batch 450 Loss 0.0425 Accuracy 0.9798\n",
      "Epoch 9 Batch 500 Loss 0.0423 Accuracy 0.9798\n",
      "Epoch 9 Batch 550 Loss 0.0419 Accuracy 0.9799\n",
      "Epoch 9 Batch 600 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 650 Loss 0.0423 Accuracy 0.9798\n",
      "Epoch 9 Batch 700 Loss 0.0424 Accuracy 0.9798\n",
      "Epoch 9 Batch 750 Loss 0.0423 Accuracy 0.9798\n",
      "Epoch 9 Batch 800 Loss 0.0424 Accuracy 0.9798\n",
      "Epoch 9 Batch 850 Loss 0.0423 Accuracy 0.9798\n",
      "Epoch 9 Batch 900 Loss 0.0423 Accuracy 0.9798\n",
      "Epoch 9 Batch 950 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 1000 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 1050 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 1100 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 1150 Loss 0.0421 Accuracy 0.9799\n",
      "Epoch 9 Batch 1200 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 1250 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 1300 Loss 0.0422 Accuracy 0.9799\n",
      "Epoch 9 Batch 1350 Loss 0.0422 Accuracy 0.9799\n",
      "Epoch 9 Batch 1400 Loss 0.0422 Accuracy 0.9799\n",
      "Epoch 9 Batch 1450 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 1500 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 1550 Loss 0.0421 Accuracy 0.9799\n",
      "Epoch 9 Batch 1600 Loss 0.0422 Accuracy 0.9799\n",
      "Epoch 9 Batch 1650 Loss 0.0421 Accuracy 0.9799\n",
      "Epoch 9 Batch 1700 Loss 0.0421 Accuracy 0.9799\n",
      "Epoch 9 Batch 1750 Loss 0.0422 Accuracy 0.9799\n",
      "Epoch 9 Batch 1800 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 1850 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 1900 Loss 0.0422 Accuracy 0.9799\n",
      "Epoch 9 Batch 1950 Loss 0.0422 Accuracy 0.9799\n",
      "Epoch 9 Batch 2000 Loss 0.0422 Accuracy 0.9799\n",
      "Epoch 9 Batch 2050 Loss 0.0422 Accuracy 0.9799\n",
      "Epoch 9 Batch 2100 Loss 0.0421 Accuracy 0.9799\n",
      "Epoch 9 Batch 2150 Loss 0.0421 Accuracy 0.9799\n",
      "Epoch 9 Batch 2200 Loss 0.0421 Accuracy 0.9799\n",
      "Epoch 9 Batch 2250 Loss 0.0421 Accuracy 0.9799\n",
      "Epoch 9 Batch 2300 Loss 0.0421 Accuracy 0.9799\n",
      "Epoch 9 Batch 2350 Loss 0.0422 Accuracy 0.9798\n",
      "Epoch 9 Batch 2400 Loss 0.0421 Accuracy 0.9799\n",
      "Epoch 9 Batch 2450 Loss 0.0421 Accuracy 0.9799\n",
      "Epoch 9 Batch 2500 Loss 0.0420 Accuracy 0.9799\n",
      "Epoch 9 Batch 2550 Loss 0.0420 Accuracy 0.9799\n",
      "Epoch 9 Batch 2600 Loss 0.0420 Accuracy 0.9799\n",
      "Epoch 9 Batch 2650 Loss 0.0420 Accuracy 0.9799\n",
      "Epoch 9 Batch 2700 Loss 0.0419 Accuracy 0.9799\n",
      "Epoch 9 Batch 2750 Loss 0.0419 Accuracy 0.9799\n",
      "Epoch 9 Batch 2800 Loss 0.0419 Accuracy 0.9800\n",
      "Epoch 9 Batch 2850 Loss 0.0419 Accuracy 0.9800\n",
      "Epoch 9 Batch 2900 Loss 0.0419 Accuracy 0.9800\n",
      "Epoch 9 Batch 2950 Loss 0.0418 Accuracy 0.9800\n",
      "Epoch 9 Batch 3000 Loss 0.0419 Accuracy 0.9800\n",
      "Epoch 9 Batch 3050 Loss 0.0418 Accuracy 0.9800\n",
      "Epoch 9 Batch 3100 Loss 0.0418 Accuracy 0.9800\n",
      "Epoch 9 Batch 3150 Loss 0.0418 Accuracy 0.9800\n",
      "Epoch 9 Batch 3200 Loss 0.0418 Accuracy 0.9800\n",
      "Epoch 9 Batch 3250 Loss 0.0418 Accuracy 0.9800\n",
      "Epoch 9 Batch 3300 Loss 0.0417 Accuracy 0.9800\n",
      "Epoch 9 Batch 3350 Loss 0.0417 Accuracy 0.9800\n",
      "Epoch 9 Batch 3400 Loss 0.0417 Accuracy 0.9800\n",
      "Epoch 9 Batch 3450 Loss 0.0417 Accuracy 0.9800\n",
      "Epoch 9 Batch 3500 Loss 0.0417 Accuracy 0.9800\n",
      "Epoch 9 Batch 3550 Loss 0.0417 Accuracy 0.9800\n",
      "Epoch 9 Batch 3600 Loss 0.0417 Accuracy 0.9800\n",
      "Epoch 9 Batch 3650 Loss 0.0417 Accuracy 0.9800\n",
      "Epoch 9 Batch 3700 Loss 0.0417 Accuracy 0.9800\n",
      "Epoch 9 Batch 3750 Loss 0.0417 Accuracy 0.9800\n",
      "Epoch 9 Batch 3800 Loss 0.0417 Accuracy 0.9800\n",
      "Epoch 9 Batch 3850 Loss 0.0416 Accuracy 0.9801\n",
      "Epoch 9 Batch 3900 Loss 0.0416 Accuracy 0.9800\n",
      "Epoch 9 Batch 3950 Loss 0.0416 Accuracy 0.9800\n",
      "Epoch 9 Batch 4000 Loss 0.0416 Accuracy 0.9800\n",
      "Epoch 9 Batch 4050 Loss 0.0416 Accuracy 0.9800\n",
      "Epoch 9 Batch 4100 Loss 0.0416 Accuracy 0.9800\n",
      "Epoch 9 Batch 4150 Loss 0.0416 Accuracy 0.9801\n",
      "Epoch 9 Batch 4200 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4250 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4300 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4350 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4400 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4450 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4500 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4550 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4600 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4650 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4700 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4750 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4800 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4850 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4900 Loss 0.0415 Accuracy 0.9801\n",
      "Epoch 9 Batch 4950 Loss 0.0414 Accuracy 0.9801\n",
      "Epoch 9 Batch 5000 Loss 0.0414 Accuracy 0.9801\n",
      "Epoch 9 Batch 5050 Loss 0.0414 Accuracy 0.9801\n",
      "Epoch 9 Batch 5100 Loss 0.0414 Accuracy 0.9801\n",
      "Epoch 9 Batch 5150 Loss 0.0414 Accuracy 0.9801\n",
      "Epoch 9 Batch 5200 Loss 0.0414 Accuracy 0.9801\n",
      "Epoch 9 Batch 5250 Loss 0.0414 Accuracy 0.9801\n",
      "Epoch 9 Batch 5300 Loss 0.0414 Accuracy 0.9801\n",
      "Epoch 9 Batch 5350 Loss 0.0414 Accuracy 0.9801\n",
      "Epoch 9 Batch 5400 Loss 0.0414 Accuracy 0.9801\n",
      "Epoch 9 Batch 5450 Loss 0.0414 Accuracy 0.9801\n",
      "Epoch 9 Batch 5500 Loss 0.0413 Accuracy 0.9801\n",
      "Epoch 9 Batch 5550 Loss 0.0413 Accuracy 0.9801\n",
      "Epoch 9 Batch 5600 Loss 0.0413 Accuracy 0.9801\n",
      "Epoch 9 Batch 5650 Loss 0.0413 Accuracy 0.9802\n",
      "Epoch 9 Batch 5700 Loss 0.0413 Accuracy 0.9802\n",
      "Epoch 9 Batch 5750 Loss 0.0413 Accuracy 0.9802\n",
      "Epoch 9 Batch 5800 Loss 0.0413 Accuracy 0.9802\n",
      "Epoch 9 Batch 5850 Loss 0.0412 Accuracy 0.9802\n",
      "Epoch 9 Batch 5900 Loss 0.0412 Accuracy 0.9802\n",
      "Epoch 9 Batch 5950 Loss 0.0412 Accuracy 0.9802\n",
      "Epoch 9 Batch 6000 Loss 0.0412 Accuracy 0.9802\n",
      "Epoch 9 Batch 6050 Loss 0.0412 Accuracy 0.9802\n",
      "Epoch 9 Batch 6100 Loss 0.0411 Accuracy 0.9802\n",
      "Epoch 9 Batch 6150 Loss 0.0411 Accuracy 0.9802\n",
      "Epoch 9 Batch 6200 Loss 0.0411 Accuracy 0.9802\n",
      "Epoch 9 Loss 0.0411 Accuracy 0.9802\n",
      "Time taken for 1 epoch: 596.46 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0338 Accuracy 0.9845\n",
      "Epoch 10 Batch 50 Loss 0.0387 Accuracy 0.9809\n",
      "Epoch 10 Batch 100 Loss 0.0398 Accuracy 0.9805\n",
      "Epoch 10 Batch 150 Loss 0.0403 Accuracy 0.9805\n",
      "Epoch 10 Batch 200 Loss 0.0407 Accuracy 0.9805\n",
      "Epoch 10 Batch 250 Loss 0.0405 Accuracy 0.9805\n",
      "Epoch 10 Batch 300 Loss 0.0408 Accuracy 0.9804\n",
      "Epoch 10 Batch 350 Loss 0.0403 Accuracy 0.9806\n",
      "Epoch 10 Batch 400 Loss 0.0402 Accuracy 0.9807\n",
      "Epoch 10 Batch 450 Loss 0.0401 Accuracy 0.9807\n",
      "Epoch 10 Batch 500 Loss 0.0400 Accuracy 0.9806\n",
      "Epoch 10 Batch 550 Loss 0.0398 Accuracy 0.9807\n",
      "Epoch 10 Batch 600 Loss 0.0400 Accuracy 0.9806\n",
      "Epoch 10 Batch 650 Loss 0.0400 Accuracy 0.9806\n",
      "Epoch 10 Batch 700 Loss 0.0400 Accuracy 0.9806\n",
      "Epoch 10 Batch 750 Loss 0.0399 Accuracy 0.9806\n",
      "Epoch 10 Batch 800 Loss 0.0399 Accuracy 0.9806\n",
      "Epoch 10 Batch 850 Loss 0.0400 Accuracy 0.9806\n",
      "Epoch 10 Batch 900 Loss 0.0399 Accuracy 0.9806\n",
      "Epoch 10 Batch 950 Loss 0.0399 Accuracy 0.9807\n",
      "Epoch 10 Batch 1000 Loss 0.0398 Accuracy 0.9807\n",
      "Epoch 10 Batch 1050 Loss 0.0398 Accuracy 0.9807\n",
      "Epoch 10 Batch 1100 Loss 0.0398 Accuracy 0.9807\n",
      "Epoch 10 Batch 1150 Loss 0.0397 Accuracy 0.9807\n",
      "Epoch 10 Batch 1200 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1250 Loss 0.0397 Accuracy 0.9807\n",
      "Epoch 10 Batch 1300 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1350 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1400 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1450 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1500 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1550 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1600 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1650 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1700 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1750 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1800 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1850 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 1900 Loss 0.0397 Accuracy 0.9807\n",
      "Epoch 10 Batch 1950 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 2000 Loss 0.0397 Accuracy 0.9807\n",
      "Epoch 10 Batch 2050 Loss 0.0396 Accuracy 0.9807\n",
      "Epoch 10 Batch 2100 Loss 0.0396 Accuracy 0.9808\n",
      "Epoch 10 Batch 2150 Loss 0.0396 Accuracy 0.9808\n",
      "Epoch 10 Batch 2200 Loss 0.0396 Accuracy 0.9808\n",
      "Epoch 10 Batch 2250 Loss 0.0396 Accuracy 0.9808\n",
      "Epoch 10 Batch 2300 Loss 0.0395 Accuracy 0.9808\n",
      "Epoch 10 Batch 2350 Loss 0.0395 Accuracy 0.9808\n",
      "Epoch 10 Batch 2400 Loss 0.0395 Accuracy 0.9808\n",
      "Epoch 10 Batch 2450 Loss 0.0395 Accuracy 0.9808\n",
      "Epoch 10 Batch 2500 Loss 0.0394 Accuracy 0.9808\n",
      "Epoch 10 Batch 2550 Loss 0.0394 Accuracy 0.9808\n",
      "Epoch 10 Batch 2600 Loss 0.0395 Accuracy 0.9808\n",
      "Epoch 10 Batch 2650 Loss 0.0394 Accuracy 0.9808\n",
      "Epoch 10 Batch 2700 Loss 0.0394 Accuracy 0.9808\n",
      "Epoch 10 Batch 2750 Loss 0.0394 Accuracy 0.9809\n",
      "Epoch 10 Batch 2800 Loss 0.0393 Accuracy 0.9809\n",
      "Epoch 10 Batch 2850 Loss 0.0393 Accuracy 0.9809\n",
      "Epoch 10 Batch 2900 Loss 0.0393 Accuracy 0.9809\n",
      "Epoch 10 Batch 2950 Loss 0.0393 Accuracy 0.9809\n",
      "Epoch 10 Batch 3000 Loss 0.0393 Accuracy 0.9809\n",
      "Epoch 10 Batch 3050 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3100 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3150 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3200 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3250 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3300 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3350 Loss 0.0393 Accuracy 0.9809\n",
      "Epoch 10 Batch 3400 Loss 0.0393 Accuracy 0.9809\n",
      "Epoch 10 Batch 3450 Loss 0.0393 Accuracy 0.9809\n",
      "Epoch 10 Batch 3500 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3550 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3600 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3650 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3700 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3750 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3800 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3850 Loss 0.0391 Accuracy 0.9810\n",
      "Epoch 10 Batch 3900 Loss 0.0392 Accuracy 0.9809\n",
      "Epoch 10 Batch 3950 Loss 0.0391 Accuracy 0.9810\n",
      "Epoch 10 Batch 4000 Loss 0.0392 Accuracy 0.9810\n",
      "Epoch 10 Batch 4050 Loss 0.0392 Accuracy 0.9810\n",
      "Epoch 10 Batch 4100 Loss 0.0391 Accuracy 0.9810\n",
      "Epoch 10 Batch 4150 Loss 0.0391 Accuracy 0.9810\n",
      "Epoch 10 Batch 4200 Loss 0.0391 Accuracy 0.9810\n",
      "Epoch 10 Batch 4250 Loss 0.0391 Accuracy 0.9810\n",
      "Epoch 10 Batch 4300 Loss 0.0391 Accuracy 0.9810\n",
      "Epoch 10 Batch 4350 Loss 0.0391 Accuracy 0.9810\n",
      "Epoch 10 Batch 4400 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 4450 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 4500 Loss 0.0391 Accuracy 0.9810\n",
      "Epoch 10 Batch 4550 Loss 0.0391 Accuracy 0.9810\n",
      "Epoch 10 Batch 4600 Loss 0.0391 Accuracy 0.9810\n",
      "Epoch 10 Batch 4650 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 4700 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 4750 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 4800 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 4850 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 4900 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 4950 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 5000 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 5050 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 5100 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 5150 Loss 0.0389 Accuracy 0.9810\n",
      "Epoch 10 Batch 5200 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 5250 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 5300 Loss 0.0390 Accuracy 0.9810\n",
      "Epoch 10 Batch 5350 Loss 0.0389 Accuracy 0.9810\n",
      "Epoch 10 Batch 5400 Loss 0.0389 Accuracy 0.9810\n",
      "Epoch 10 Batch 5450 Loss 0.0389 Accuracy 0.9810\n",
      "Epoch 10 Batch 5500 Loss 0.0389 Accuracy 0.9810\n",
      "Epoch 10 Batch 5550 Loss 0.0389 Accuracy 0.9810\n",
      "Epoch 10 Batch 5600 Loss 0.0389 Accuracy 0.9810\n",
      "Epoch 10 Batch 5650 Loss 0.0389 Accuracy 0.9810\n",
      "Epoch 10 Batch 5700 Loss 0.0389 Accuracy 0.9810\n",
      "Epoch 10 Batch 5750 Loss 0.0389 Accuracy 0.9810\n",
      "Epoch 10 Batch 5800 Loss 0.0389 Accuracy 0.9810\n",
      "Epoch 10 Batch 5850 Loss 0.0388 Accuracy 0.9810\n",
      "Epoch 10 Batch 5900 Loss 0.0388 Accuracy 0.9810\n",
      "Epoch 10 Batch 5950 Loss 0.0388 Accuracy 0.9810\n",
      "Epoch 10 Batch 6000 Loss 0.0388 Accuracy 0.9810\n",
      "Epoch 10 Batch 6050 Loss 0.0388 Accuracy 0.9811\n",
      "Epoch 10 Batch 6100 Loss 0.0388 Accuracy 0.9811\n",
      "Epoch 10 Batch 6150 Loss 0.0387 Accuracy 0.9811\n",
      "Epoch 10 Batch 6200 Loss 0.0387 Accuracy 0.9811\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
      "Epoch 10 Loss 0.0387 Accuracy 0.9811\n",
      "Time taken for 1 epoch: 596.80 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    # inp -> nocanonic, tar -> canonic\n",
    "    i=0\n",
    "    batch = 0\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    while True:\n",
    "        i=i+64   \n",
    "        if i>=ds_x.shape[0]:\n",
    "            break\n",
    "        inp = tf.ragged.constant(ds_x[i:i+64],dtype=tf.int64).to_tensor()\n",
    "        tar = tf.ragged.constant(ds_y[i:i+64],dtype=tf.int64).to_tensor()    \n",
    "        train_step(inp, tar)\n",
    "        if batch % 50 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "        batch = batch + 1\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
    "\n",
    "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "    print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee7411ce-380d-4c15-ac48-d4b50924d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=40):\n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "    sentence = tf.ragged.constant(np.array(tokenizer.encode(sentence, add_special_tokens=True)).reshape(1,-1),dtype=tf.int64).to_tensor()\n",
    "  \n",
    "    encoder_input = sentence\n",
    "  \n",
    "    # as the target is english, the first word to the transformer should be the\n",
    "    # english start token.\n",
    "    end = tf.ragged.constant(2,dtype=tf.int64)\n",
    "#     output = tf.convert_to_tensor([start])\n",
    "    output = tf.ragged.constant(np.array(0).reshape(1,-1),dtype=tf.int64).to_tensor()\n",
    "  \n",
    "    for i in range(max_length):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "  \n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input,\n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "  \n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "  \n",
    "        predicted_id = tf.argmax(predictions, axis=-1)\n",
    "  \n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "  \n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == end:\n",
    "            break\n",
    "  \n",
    "    pred=''\n",
    "    keys = pd.DataFrame(tokenizer.vocab.keys())\n",
    "    values = pd.DataFrame(tokenizer.vocab.values())\n",
    "    dic = dict()\n",
    "    for i in range(keys.shape[0]):\n",
    "        dic[values.iloc[i,0]]=(keys.iloc[i,0])\n",
    "    for j in range (output.numpy().shape[1]):\n",
    "        if output.numpy()[0,j] != 0 and output.numpy()[0,j] != 2:\n",
    "            pred=pred+dic[output.numpy()[0,j]]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26fac83b-da76-4dbe-a0c8-cff717235f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_smi(smi):\n",
    "    m = Chem.MolFromSmiles(smi,sanitize=False)\n",
    "    if m is None:\n",
    "        return 'invalid SMILES'\n",
    "    else:\n",
    "        try:\n",
    "            Chem.SanitizeMol(m)\n",
    "            return True\n",
    "        except:\n",
    "            return 'invalid chemistry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a4bc9c3-b741-49ed-8133-a0ff29c299d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(real,pred):\n",
    "    ref = Chem.MolFromSmiles(real)\n",
    "    mol1 = Chem.MolFromSmiles(pred)\n",
    "    fp1 = Chem.RDKFingerprint(ref)\n",
    "    fp2 = Chem.RDKFingerprint(mol1)\n",
    "\n",
    "    Tan  =DataStructs.TanimotoSimilarity(fp1,fp2)\n",
    "    return Tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ca5e80c-40dd-4ce0-9dae-87a993903ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(smi):\n",
    "    print(smi)\n",
    "    m = Chem.MolFromSmiles(smi)\n",
    "    fig = Draw.MolToMPL(m, size=size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b60ed54-d010-4b49-86f5-e94a083ee879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [17:51:22] SMILES Parse Error: unclosed ring for input: 'C[C@H](Nc1c(C#N)c(=O)n(C)c(=O)n1C)c1ccc(OC(C)C)'\n",
      "RDKit ERROR: [17:51:33] SMILES Parse Error: unclosed ring for input: '[NH3+]COc1cc(CNC(=O)C(C)C)ccc1OC1'\n"
     ]
    }
   ],
   "source": [
    "pred_smi=[]\n",
    "for i in range(10):\n",
    "    try:\n",
    "        row=[]\n",
    "#         print(\"Haqiqiy smiles:\",test_df.iloc[i,0])\n",
    "#         m = Chem.MolFromSmiles(test_df.iloc[i,0])\n",
    "#         fig = Draw.MolToMPL(m, size=size)    \n",
    "        sentence = test_df.iloc[random.randint(0,50000),0]\n",
    "        pred = evaluate(sentence)\n",
    "        row.append(sentence)\n",
    "        row.append(pred)\n",
    "        check=check_smi(pred)\n",
    "        if check == True:\n",
    "            row.append(True)\n",
    "            row.append(similarity(sentence,pred))\n",
    "        else:\n",
    "            row.append(check)\n",
    "            row.append(0)\n",
    "        pred_smi.append(row)\n",
    "#         print(\"Bashorat smiles:\",pred)\n",
    "#         pred_smi.append(pred)\n",
    "#         m = Chem.MolFromSmiles(pred)\n",
    "#         fig = Draw.MolToMPL(m, size=size) \n",
    "#         print()\n",
    "    except Exception as ex:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e52331-899c-4ce4-a93f-91d9b0b9983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_smi).to_excel('pred_smi.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff60fc0-6836-4a6b-b8a0-5fe251663f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Pred</th>\n",
       "      <th>check</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N(C(=O)C)c1ccc(CNC(=O)CNC(=O)c2c(OC)cccc2)cc1</td>\n",
       "      <td>CNC(=O)Nc1ccc(CNC(=O)CNC(=O)c2ccccc2OC)cc1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.881443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C(n1nc(N)cc1C)Oc1ccc(Cl)cc1Cl</td>\n",
       "      <td>c1cc(N)nn1COc1ccc(Cl)cc1Cl</td>\n",
       "      <td>True</td>\n",
       "      <td>0.797732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cn1c(=O)c(C#N)c(N[C@H](c2ccc(OC(C)C)cc2)C)n(C)...</td>\n",
       "      <td>C[C@H](Nc1c(C#N)c(=O)n(C)c(=O)n1C)c1ccc(OC(C)C)</td>\n",
       "      <td>invalid SMILES</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O=S(=O)(N[C@@H]1CCCC[C@H]1O)c1cc(N)c(Cl)cc1C</td>\n",
       "      <td>c1cc(Cl)c(N)cc1S(=O)(=O)N[C@@H]1CCCC[C@@H]1O</td>\n",
       "      <td>True</td>\n",
       "      <td>0.777624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1(C)nc2ccc(NCC(NC(=O)NC)=O)cc2s1</td>\n",
       "      <td>C=C(CNC(=O)Nc1ccc2nc(C)sc2c1)NC(=O)NC</td>\n",
       "      <td>True</td>\n",
       "      <td>0.702156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C1[C@@H](COc2c(OC)cc(CNC(=O)C(C)C)cc2)OCC1</td>\n",
       "      <td>[NH3+]COc1cc(CNC(=O)C(C)C)ccc1OC1</td>\n",
       "      <td>invalid SMILES</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C([NH2+][C@@H]1C[C@H](COC)CCC1)C</td>\n",
       "      <td>[NH2+][C@H]1CCC[C@@H](COC)C1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C(N(C(N1CCC(OCC([O-])=O)CC1)=O)CC)C(O)(C)C</td>\n",
       "      <td>N/C(=O)N1CCC(OCC(=O)[O-])CC1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.651351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c1cccc2c1SC[C@H]2C[NH2+]C[C@@H](C)CCCl</td>\n",
       "      <td>[NH2+]C[C@H](CCCl)C[C@H]1CSc2ccccc21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C(c1c(C)c(NC(CSc2nc(C)n[nH]2)=O)ccc1)SC(C)C</td>\n",
       "      <td>c1n[nH]c(SCC(=O)Nc2cccc(CSC(C)C)c2C)n1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.922099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Real  \\\n",
       "0      N(C(=O)C)c1ccc(CNC(=O)CNC(=O)c2c(OC)cccc2)cc1   \n",
       "1                      C(n1nc(N)cc1C)Oc1ccc(Cl)cc1Cl   \n",
       "2  Cn1c(=O)c(C#N)c(N[C@H](c2ccc(OC(C)C)cc2)C)n(C)...   \n",
       "3       O=S(=O)(N[C@@H]1CCCC[C@H]1O)c1cc(N)c(Cl)cc1C   \n",
       "4                  c1(C)nc2ccc(NCC(NC(=O)NC)=O)cc2s1   \n",
       "5         C1[C@@H](COc2c(OC)cc(CNC(=O)C(C)C)cc2)OCC1   \n",
       "6                   C([NH2+][C@@H]1C[C@H](COC)CCC1)C   \n",
       "7         C(N(C(N1CCC(OCC([O-])=O)CC1)=O)CC)C(O)(C)C   \n",
       "8             c1cccc2c1SC[C@H]2C[NH2+]C[C@@H](C)CCCl   \n",
       "9        C(c1c(C)c(NC(CSc2nc(C)n[nH]2)=O)ccc1)SC(C)C   \n",
       "\n",
       "                                              Pred           check  Similarity  \n",
       "0       CNC(=O)Nc1ccc(CNC(=O)CNC(=O)c2ccccc2OC)cc1            True    0.881443  \n",
       "1                       c1cc(N)nn1COc1ccc(Cl)cc1Cl            True    0.797732  \n",
       "2  C[C@H](Nc1c(C#N)c(=O)n(C)c(=O)n1C)c1ccc(OC(C)C)  invalid SMILES    0.000000  \n",
       "3     c1cc(Cl)c(N)cc1S(=O)(=O)N[C@@H]1CCCC[C@@H]1O            True    0.777624  \n",
       "4            C=C(CNC(=O)Nc1ccc2nc(C)sc2c1)NC(=O)NC            True    0.702156  \n",
       "5                [NH3+]COc1cc(CNC(=O)C(C)C)ccc1OC1  invalid SMILES    0.000000  \n",
       "6                     [NH2+][C@H]1CCC[C@@H](COC)C1            True    0.709677  \n",
       "7                     N/C(=O)N1CCC(OCC(=O)[O-])CC1            True    0.651351  \n",
       "8             [NH2+]C[C@H](CCCl)C[C@H]1CSc2ccccc21            True    0.538462  \n",
       "9           c1n[nH]c(SCC(=O)Nc2cccc(CSC(C)C)c2C)n1            True    0.922099  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_smi=pd.read_excel('pred_smi.xlsx')\n",
    "pred_smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "157d936e-fbb8-4a92-8b1f-1b2d7dfc06f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNC(=O)Nc1ccc(CNC(=O)CNC(=O)c2ccccc2OC)cc1\n",
      "c1cc(N)nn1COc1ccc(Cl)cc1Cl\n",
      "c1cc(Cl)c(N)cc1S(=O)(=O)N[C@@H]1CCCC[C@@H]1O\n",
      "C=C(CNC(=O)Nc1ccc2nc(C)sc2c1)NC(=O)NC\n",
      "[NH2+][C@H]1CCC[C@@H](COC)C1\n",
      "N/C(=O)N1CCC(OCC(=O)[O-])CC1\n",
      "[NH2+]C[C@H](CCCl)C[C@H]1CSc2ccccc21\n",
      "c1n[nH]c(SCC(=O)Nc2cccc(CSC(C)C)c2C)n1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 86.4x86.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 86.4x86.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 86.4x86.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 86.4x86.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 86.4x86.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 86.4x86.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 86.4x86.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 86.4x86.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if pred_smi.iloc[i,2]==True:\n",
    "        draw(pred_smi.iloc[i,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24083aa-0a9a-4da1-8f48-c5fd708acf30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
